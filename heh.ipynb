{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  tf.random.set_seed(seed)\n",
    "\n",
    "SEED = 22\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 132, 1536, 1599, 1662]\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from itertools import accumulate\n",
    "\n",
    "landmark_lens = (\n",
    "    (33, 4),\n",
    "    (468, 3),\n",
    "    (21, 3),\n",
    "    (21, 3)\n",
    ")\n",
    "landmark_locs = list(accumulate(landmark_lens, lambda a, b: a + b[0]*b[1], initial=0))\n",
    "landmarks_len = reduce(lambda r, loc: r + loc[0] * loc[1], landmark_lens, 0)\n",
    "print(landmark_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'tracks_binary'\n",
    "labels = [label for label in os.listdir(data_folder) if os.path.isdir(f'{data_folder}/{label}')]\n",
    "NUM_CLASSES = len(labels)\n",
    "\n",
    "labels_tensor = tf.constant(labels)\n",
    "ids_tensor = tf.constant(range(len(labels)))\n",
    "\n",
    "ids_from_labels = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        labels_tensor,\n",
    "        ids_tensor\n",
    "    ),\n",
    "    default_value=-1\n",
    ")\n",
    "\n",
    "labels_from_ids = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        ids_tensor,\n",
    "        labels_tensor\n",
    "    ),\n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "def to_categorical(label):\n",
    "    return tf.one_hot(\n",
    "        ids_from_labels.lookup(label),\n",
    "        depth=NUM_CLASSES\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_binary(file_path):\n",
    "    label = tf.strings.split(file_path, os.sep)[-2]\n",
    "\n",
    "    raw = tf.io.read_file(file_path)\n",
    "    data = tf.io.decode_raw(raw, tf.float32)\n",
    "    data = tf.reshape(data, [-1, landmarks_len])\n",
    "\n",
    "    pose = tf.reshape(data[:, 0:132], [-1, 33, 4])\n",
    "    face = tf.reshape(data[:, 132:1536], [-1, 468, 3])\n",
    "    lh = tf.reshape(data[:, 1536:1599], [-1, 21, 3])\n",
    "    rh = tf.reshape(data[:, 1599:1662], [-1, 21, 3])\n",
    "\n",
    "    return (pose, face, lh, rh), to_categorical(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import reduce_max, reduce_min\n",
    "\n",
    "FRAMES = 64\n",
    "\n",
    "def flatten(x):\n",
    "    pose = tf.reshape(x[0], shape=[-1, 132])\n",
    "    face = tf.reshape(x[1], shape=[-1, 1404])\n",
    "    lh = tf.reshape(x[2], shape=[-1, 63])\n",
    "    rh = tf.reshape(x[3], shape=[-1, 63])\n",
    "    return tf.concat([pose, face, lh, rh], axis=1)\n",
    "\n",
    "\n",
    "def random_window(x):\n",
    "    def pad(x):\n",
    "        missing = FRAMES - size\n",
    "        start_pad = tf.math.ceil(missing / 2)\n",
    "        end_pad = tf.math.floor(missing / 2)\n",
    "        return tf.concat([\n",
    "            tf.tile([x[0]], [start_pad, 1]),\n",
    "            x,\n",
    "            tf.tile([x[-1]], [end_pad, 1])\n",
    "        ], axis=0)\n",
    "\n",
    "    def random_slice(x):\n",
    "        i = tf.random.uniform(shape=(), maxval=size+1-FRAMES, dtype=tf.int32)\n",
    "        return x[i: i+FRAMES]\n",
    "\n",
    "    size = tf.shape(x)[0]\n",
    "    print(size)\n",
    "    return tf.cond(\n",
    "        size < FRAMES,\n",
    "        lambda: pad(x),\n",
    "        lambda: random_slice(x)\n",
    "    )\n",
    "    \n",
    "def calc_bounding(pose, face, lh, rh):\n",
    "    max_x = reduce_max(tf.stack([reduce_max(pose[:, :, :1]), reduce_max(face[:, :, :1]), reduce_max(lh[:, :, :1]), reduce_max(rh[:, :, :1])], axis=0))\n",
    "    min_x = reduce_min(tf.stack([reduce_min(pose[:, :, :1]), reduce_min(face[:, :, :1]), reduce_min(lh[:, :, :1]), reduce_min(rh[:, :, :1])], axis=0))\n",
    "    \n",
    "    max_y = reduce_max(tf.stack([reduce_max(pose[:, :, 1:2]), reduce_max(face[:, :, 1:2]), reduce_max(lh[:, :, 1:2]), reduce_max(rh[:, :, 1:2])], axis=0))\n",
    "    min_y = reduce_min(tf.stack([reduce_min(pose[:, :, 1:2]), reduce_min(face[:, :, 1:2]), reduce_min(lh[:, :, 1:2]), reduce_min(rh[:, :, 1:2])], axis=0))\n",
    "\n",
    "    window = tf.cast((max_x - min_x, max_y - min_y), dtype=tf.float32)\n",
    "    mid = ((max_x + min_x)/2, (max_y + min_y)/2)\n",
    "    return (window, mid)\n",
    "\n",
    "def scale(x, factor):\n",
    "    pose, face, lh, rh = x[0], x[1], x[2], x[3]\n",
    "    window, mid = calc_bounding(pose, face, lh, rh)\n",
    "    scale = factor * window\n",
    "    pose_shape, face_shape, lh_shape, rh_shape = tf.shape(pose), tf.shape(face), tf.shape(lh), tf.shape(rh)\n",
    "    pose_center = tf.tile([[[mid[0], mid[1], 0, 0]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    face_center = tf.tile([[[mid[0], mid[1], 0]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_center = tf.tile([[[mid[0], mid[1], 0]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_center = tf.tile([[[mid[0], mid[1], 0]]], [rh_shape[0], rh_shape[1], 1])\n",
    "    \n",
    "    pose_scale = tf.tile([[[scale[0], scale[1], 1, 1]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    face_scale = tf.tile([[[scale[0], scale[1], 1]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_scale = tf.tile([[[scale[0], scale[1], 1]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_scale = tf.tile([[[scale[0], scale[1], 1]]], [rh_shape[0], rh_shape[1], 1])\n",
    "    \n",
    "    scaled_pose = pose_center + (pose - pose_center) * pose_scale\n",
    "    scaled_face = face_center + (face - face_center) * face_scale\n",
    "    scaled_lh = lh_center + (lh - lh_center) * lh_scale\n",
    "    scaled_rh = rh_center + (rh - rh_center) * rh_scale\n",
    "\n",
    "    return (scaled_pose, scaled_face, scaled_lh, scaled_rh)\n",
    "\n",
    "def random_translation(x):\n",
    "    pose, face, lh, rh = x[0], x[1], x[2], x[3]\n",
    "    magnitude = tf.random.uniform(shape=[2], minval=-0.25, maxval=0.25)\n",
    "    pose_shape, face_shape, lh_shape, rh_shape = tf.shape(pose), tf.shape(face), tf.shape(lh), tf.shape(rh)\n",
    "    \n",
    "    pose_trans = tf.tile([[[magnitude[0], magnitude[1], 0, 0]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    face_trans = tf.tile([[[magnitude[0], magnitude[1], 0]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_trans = tf.tile([[[magnitude[0], magnitude[1], 0]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_trans = tf.tile([[[magnitude[0], magnitude[1], 0]]], [rh_shape[0], rh_shape[1], 1])\n",
    "\n",
    "    return (pose+pose_trans, face+face_trans, lh+lh_trans, rh+rh_trans)\n",
    "    \n",
    "def flip(x):\n",
    "    pose, face, lh, rh = x[0], x[1], x[2], x[3]\n",
    "    pose_shape, face_shape, lh_shape, rh_shape = tf.shape(pose), tf.shape(face), tf.shape(lh), tf.shape(rh)\n",
    "    \n",
    "    pose_neg = tf.tile([[[-1.0, 1, 1, 1]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    face_neg = tf.tile([[[-1.0, 1, 1]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_neg = tf.tile([[[-1.0, 1, 1]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_neg = tf.tile([[[-1.0, 1, 1]]], [rh_shape[0], rh_shape[1], 1])\n",
    "    \n",
    "    pose_trans = tf.tile([[[1.0, 0, 0, 0]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    face_trans = tf.tile([[[1.0, 0, 0]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_trans = tf.tile([[[1.0, 0, 0]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_trans = tf.tile([[[1.0, 0, 0]]], [rh_shape[0], rh_shape[1], 1])\n",
    "\n",
    "    flipped_pose = pose_trans + pose * pose_neg\n",
    "    flipped_face = face_trans + face * face_neg\n",
    "    flipped_lh = lh_trans + lh * lh_neg\n",
    "    flipped_rh = rh_trans + rh * rh_neg\n",
    "    \n",
    "    return (flipped_pose, flipped_face, flipped_lh, flipped_rh)\n",
    "    \n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (random_translation(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.map(lambda x, y: (scale(x, 0.1), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.map(lambda x, y: (flip(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "               \n",
    "    ds = ds.map(lambda x, y: (flatten(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    ds = ds.map(lambda x, y: (random_window(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000, seed=SEED)\n",
    "        \n",
    "    ds = ds.batch(32)\n",
    "\n",
    "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_split(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=1000):\n",
    "  assert (train_split + test_split + val_split) == 1\n",
    "  \n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(shuffle_size, seed=SEED)\n",
    "  \n",
    "  train_size = int(train_split * ds_size)\n",
    "  val_size = int(val_split * ds_size)\n",
    "  \n",
    "  train_ds = ds.take(train_size)\n",
    "  val_ds = ds.skip(train_size).take(val_size)\n",
    "  test_ds = ds.skip(train_size).skip(val_size)\n",
    "  \n",
    "  return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (((None, 33, 4), (None, 468, 3), (None, 21, 3), (None, 21, 3)), (10,)), types: ((tf.float32, tf.float32, tf.float32, tf.float32), tf.float32)>\n",
      "<TakeDataset shapes: (((None, 33, 4), (None, 468, 3), (None, 21, 3), (None, 21, 3)), (10,)), types: ((tf.float32, tf.float32, tf.float32, tf.float32), tf.float32)>\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "ds = tf.data.Dataset.list_files('tracks_binary_manual/*/*')\n",
    "ds = ds.map(process_binary)\n",
    "print(ds)\n",
    "train_ds, val_ds, test_ds = get_ds_split(ds, len(ds))\n",
    "print(train_ds)\n",
    "\n",
    "train_ds = prepare(train_ds, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_ds = prepare(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None, 1662), (None, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None, 1662), (None, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1 1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "from wandb.keras import WandbCallback\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrichardsonqiu\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/richardsonqiu/bi-LSTM/runs/3dyx8e0u\" target=\"_blank\">lively-tree-12</a></strong> to <a href=\"https://wandb.ai/richardsonqiu/bi-LSTM\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "  project=\"bi-LSTM\",\n",
    "  entity=\"richardsonqiu\", \n",
    "  config={\n",
    "    \"lstm_1\": 120,\n",
    "    \"layer_1\": 120,\n",
    "    \"act_1\": \"relu\",\n",
    "    \n",
    "    \"lstm_2\": 130,\n",
    "    # \"dropout_2\": 0.1,\n",
    "    \"layer_2\": 130,\n",
    "    \"act_2\": \"relu\",\n",
    "        \n",
    "    \"lstm_3\": 200,\n",
    "    \"dropout_3\": 0.2,\n",
    "    \n",
    "    \"last_layer\": NUM_CLASSES,\n",
    "    \"last_act\": \"softmax\",\n",
    "    \n",
    "    \"optimizer\": \"adam\",\n",
    "    \"init_lr\": 0.01,\n",
    "    \"loss\": \"categorical_crossentropy\",\n",
    "    \"metric\": \"accuracy\",\n",
    "    \"epoch\": 1000,\n",
    "    \"batch_size\": 32,\n",
    "    \"data\": \"manual\"  \n",
    "    })\n",
    "config = wandb.config\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(config.lstm_1, return_sequences=True), input_shape=(FRAMES, 1662)))\n",
    "model.add(Dense(config.layer_1, activation=config.act_1))\n",
    "model.add(Bidirectional(LSTM(config.lstm_2, return_sequences=True)))\n",
    "model.add(Dense(config.layer_2, activation=config.act_2))\n",
    "model.add(Bidirectional(LSTM(config.lstm_3, return_sequences=False, dropout=config.dropout_3)))\n",
    "model.add(Dense(config.last_layer, activation=config.last_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=config.init_lr)\n",
    "model.compile(optimizer=opt, loss=config.loss, metrics=[config.metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 64, 240)          1711680   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64, 120)           28920     \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64, 260)          261040    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64, 130)           33930     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 400)              529600    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                4010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,569,180\n",
      "Trainable params: 2,569,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIAL = 2\n",
    "# log_dir = os.path.join('Heh/{}'.format(TRIAL))\n",
    "# tb_callback = TensorBoard(log_dir=log_dir)\n",
    "es_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "lr_callback = ReduceLROnPlateau(monitor='val_loss', patience=20, factor=0.5, min_lr=1e-6)\n",
    "wandb_callback = WandbCallback(log_evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is unable to log validation data. When using a generator for validation_data, you must pass validation_steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 22s 1s/step - loss: 3.2901 - accuracy: 0.0688 - val_loss: 2.8605 - val_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 2s 275ms/step - loss: 2.5017 - accuracy: 0.0812 - val_loss: 2.3611 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 2s 311ms/step - loss: 2.3904 - accuracy: 0.0688 - val_loss: 2.4068 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 2s 288ms/step - loss: 2.3322 - accuracy: 0.0750 - val_loss: 2.3524 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 2.3198 - accuracy: 0.1000 - val_loss: 2.3009 - val_accuracy: 0.1500 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 2.3098 - accuracy: 0.1063 - val_loss: 2.3360 - val_accuracy: 0.1500 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 2s 261ms/step - loss: 2.3171 - accuracy: 0.1063 - val_loss: 2.3459 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 2.3147 - accuracy: 0.1125 - val_loss: 2.3277 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 2.3086 - accuracy: 0.1063 - val_loss: 2.3223 - val_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 2.3134 - accuracy: 0.0812 - val_loss: 2.3021 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 2s 270ms/step - loss: 2.3212 - accuracy: 0.0750 - val_loss: 2.3072 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 2.3110 - accuracy: 0.0938 - val_loss: 2.2806 - val_accuracy: 0.1500 - lr: 0.0100\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 2s 247ms/step - loss: 2.3158 - accuracy: 0.0688 - val_loss: 2.3323 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 2.3107 - accuracy: 0.0812 - val_loss: 2.3181 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 2.3145 - accuracy: 0.1125 - val_loss: 2.3295 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 2.3044 - accuracy: 0.1063 - val_loss: 2.2948 - val_accuracy: 0.1500 - lr: 0.0100\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 2.3165 - accuracy: 0.0938 - val_loss: 2.3089 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 2.3097 - accuracy: 0.1000 - val_loss: 2.3014 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 2.3060 - accuracy: 0.0812 - val_loss: 2.3018 - val_accuracy: 0.1500 - lr: 0.0100\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 2.3083 - accuracy: 0.0625 - val_loss: 2.3057 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 2.3035 - accuracy: 0.0875 - val_loss: 2.3030 - val_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 2s 270ms/step - loss: 2.3045 - accuracy: 0.1250 - val_loss: 2.3113 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 2.3034 - accuracy: 0.1000 - val_loss: 2.2931 - val_accuracy: 0.2000 - lr: 0.0100\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 2.3024 - accuracy: 0.1125 - val_loss: 2.3072 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 2.2984 - accuracy: 0.1125 - val_loss: 2.3135 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 2.3058 - accuracy: 0.0875 - val_loss: 2.3088 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 2.3087 - accuracy: 0.1125 - val_loss: 2.3001 - val_accuracy: 0.1500 - lr: 0.0100\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 2.3047 - accuracy: 0.1375 - val_loss: 2.3109 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 2.3003 - accuracy: 0.0688 - val_loss: 2.3107 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 2.3039 - accuracy: 0.0938 - val_loss: 2.2970 - val_accuracy: 0.2000 - lr: 0.0100\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 2.3020 - accuracy: 0.1000 - val_loss: 2.3086 - val_accuracy: 0.1500 - lr: 0.0100\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 2.3139 - accuracy: 0.0812 - val_loss: 2.3118 - val_accuracy: 0.0500 - lr: 0.0100\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 2.3084 - accuracy: 0.1063 - val_loss: 2.3122 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 2.3082 - accuracy: 0.0938 - val_loss: 2.3072 - val_accuracy: 0.0000e+00 - lr: 0.0050\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 2.3046 - accuracy: 0.0875 - val_loss: 2.3112 - val_accuracy: 0.0000e+00 - lr: 0.0050\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 2s 251ms/step - loss: 2.3066 - accuracy: 0.1000 - val_loss: 2.2982 - val_accuracy: 0.0500 - lr: 0.0050\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 2s 270ms/step - loss: 2.3049 - accuracy: 0.0750 - val_loss: 2.3019 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 2.3041 - accuracy: 0.1000 - val_loss: 2.3033 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 2.3033 - accuracy: 0.1125 - val_loss: 2.2993 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 2.3030 - accuracy: 0.0938 - val_loss: 2.3016 - val_accuracy: 0.1000 - lr: 0.0050\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 2s 310ms/step - loss: 2.3041 - accuracy: 0.1125 - val_loss: 2.3004 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 2.3042 - accuracy: 0.1000 - val_loss: 2.3182 - val_accuracy: 0.0000e+00 - lr: 0.0050\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 2s 250ms/step - loss: 2.3040 - accuracy: 0.0812 - val_loss: 2.3010 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 2.3048 - accuracy: 0.0812 - val_loss: 2.3061 - val_accuracy: 0.0500 - lr: 0.0050\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 2.3039 - accuracy: 0.0750 - val_loss: 2.2979 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 2s 317ms/step - loss: 2.3035 - accuracy: 0.1000 - val_loss: 2.2991 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 2s 274ms/step - loss: 2.3016 - accuracy: 0.1187 - val_loss: 2.3026 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 2s 272ms/step - loss: 2.3045 - accuracy: 0.0625 - val_loss: 2.3168 - val_accuracy: 0.0500 - lr: 0.0050\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 2s 253ms/step - loss: 2.3042 - accuracy: 0.0938 - val_loss: 2.2998 - val_accuracy: 0.0500 - lr: 0.0050\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 2s 250ms/step - loss: 2.3040 - accuracy: 0.1000 - val_loss: 2.2900 - val_accuracy: 0.2000 - lr: 0.0050\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 2s 265ms/step - loss: 2.3044 - accuracy: 0.1125 - val_loss: 2.3058 - val_accuracy: 0.0500 - lr: 0.0050\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 2s 240ms/step - loss: 2.3036 - accuracy: 0.0875 - val_loss: 2.2974 - val_accuracy: 0.1500 - lr: 0.0050\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 2s 253ms/step - loss: 2.3057 - accuracy: 0.1063 - val_loss: 2.2962 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 2s 236ms/step - loss: 2.3039 - accuracy: 0.0812 - val_loss: 2.3035 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 2.3020 - accuracy: 0.1125 - val_loss: 2.3015 - val_accuracy: 0.1000 - lr: 0.0025\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 2s 243ms/step - loss: 2.3037 - accuracy: 0.1000 - val_loss: 2.3058 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 2.3051 - accuracy: 0.0625 - val_loss: 2.3043 - val_accuracy: 0.1000 - lr: 0.0025\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 2.3054 - accuracy: 0.0938 - val_loss: 2.2995 - val_accuracy: 0.1500 - lr: 0.0025\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 2.3027 - accuracy: 0.1187 - val_loss: 2.3050 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 2s 268ms/step - loss: 2.3020 - accuracy: 0.1187 - val_loss: 2.3041 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 2.3042 - accuracy: 0.0938 - val_loss: 2.3041 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 2.3013 - accuracy: 0.1063 - val_loss: 2.3031 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 2s 247ms/step - loss: 2.3039 - accuracy: 0.0875 - val_loss: 2.3057 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 2s 266ms/step - loss: 2.3025 - accuracy: 0.0938 - val_loss: 2.2979 - val_accuracy: 0.2000 - lr: 0.0025\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 2.3030 - accuracy: 0.0938 - val_loss: 2.2966 - val_accuracy: 0.2000 - lr: 0.0025\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 2s 309ms/step - loss: 2.3025 - accuracy: 0.1000 - val_loss: 2.2994 - val_accuracy: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 2s 246ms/step - loss: 2.3053 - accuracy: 0.1125 - val_loss: 2.3035 - val_accuracy: 0.2500 - lr: 0.0025\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 2s 281ms/step - loss: 2.3008 - accuracy: 0.0938 - val_loss: 2.3045 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 2s 285ms/step - loss: 2.3048 - accuracy: 0.1000 - val_loss: 2.3059 - val_accuracy: 0.0500 - lr: 0.0025\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 2s 253ms/step - loss: 2.3023 - accuracy: 0.1063 - val_loss: 2.3057 - val_accuracy: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 2s 262ms/step - loss: 2.3018 - accuracy: 0.1187 - val_loss: 2.2978 - val_accuracy: 0.2000 - lr: 0.0025\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 2.3038 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000 - lr: 0.0025\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 2.3001 - accuracy: 0.1125 - val_loss: 2.3081 - val_accuracy: 0.0000e+00 - lr: 0.0012\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 2s 245ms/step - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.2960 - val_accuracy: 0.2000 - lr: 0.0012\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 2.3019 - accuracy: 0.1125 - val_loss: 2.2995 - val_accuracy: 0.1500 - lr: 0.0012\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 2s 250ms/step - loss: 2.3043 - accuracy: 0.0875 - val_loss: 2.3038 - val_accuracy: 0.1000 - lr: 0.0012\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 2.3058 - accuracy: 0.0688 - val_loss: 2.3038 - val_accuracy: 0.0500 - lr: 0.0012\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 2.2997 - accuracy: 0.1063 - val_loss: 2.3051 - val_accuracy: 0.1000 - lr: 0.0012\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 2s 265ms/step - loss: 2.3046 - accuracy: 0.0750 - val_loss: 2.3042 - val_accuracy: 0.1000 - lr: 0.0012\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 2.3013 - accuracy: 0.0938 - val_loss: 2.3002 - val_accuracy: 0.1500 - lr: 0.0012\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 2s 247ms/step - loss: 2.3019 - accuracy: 0.1063 - val_loss: 2.3017 - val_accuracy: 0.1500 - lr: 0.0012\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 2s 271ms/step - loss: 2.3027 - accuracy: 0.0875 - val_loss: 2.3041 - val_accuracy: 0.1000 - lr: 0.0012\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 2s 249ms/step - loss: 2.3037 - accuracy: 0.0938 - val_loss: 2.3024 - val_accuracy: 0.1000 - lr: 0.0012\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 2s 288ms/step - loss: 2.3026 - accuracy: 0.0938 - val_loss: 2.3062 - val_accuracy: 0.0000e+00 - lr: 0.0012\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 2.3050 - accuracy: 0.0750 - val_loss: 2.3034 - val_accuracy: 0.1000 - lr: 0.0012\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 2.3036 - accuracy: 0.1187 - val_loss: 2.2991 - val_accuracy: 0.1500 - lr: 0.0012\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 2s 259ms/step - loss: 2.3054 - accuracy: 0.1063 - val_loss: 2.3025 - val_accuracy: 0.1500 - lr: 0.0012\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 2s 289ms/step - loss: 2.3022 - accuracy: 0.1375 - val_loss: 2.3017 - val_accuracy: 0.2500 - lr: 0.0012\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 2s 267ms/step - loss: 2.3023 - accuracy: 0.1250 - val_loss: 2.3035 - val_accuracy: 0.1000 - lr: 0.0012\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 2.3040 - accuracy: 0.1063 - val_loss: 2.3021 - val_accuracy: 0.0000e+00 - lr: 0.0012\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 2.3000 - accuracy: 0.1250 - val_loss: 2.3068 - val_accuracy: 0.0500 - lr: 0.0012\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 2s 253ms/step - loss: 2.3021 - accuracy: 0.1187 - val_loss: 2.3066 - val_accuracy: 0.1000 - lr: 0.0012\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 2.3025 - accuracy: 0.1063 - val_loss: 2.3013 - val_accuracy: 0.1500 - lr: 6.2500e-04\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 2s 281ms/step - loss: 2.3030 - accuracy: 0.1063 - val_loss: 2.3032 - val_accuracy: 0.2000 - lr: 6.2500e-04\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 2.3045 - accuracy: 0.1000 - val_loss: 2.3038 - val_accuracy: 0.1500 - lr: 6.2500e-04\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 2s 262ms/step - loss: 2.3046 - accuracy: 0.1125 - val_loss: 2.3044 - val_accuracy: 0.1000 - lr: 6.2500e-04\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 2s 272ms/step - loss: 2.3038 - accuracy: 0.0500 - val_loss: 2.3041 - val_accuracy: 0.1500 - lr: 6.2500e-04\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 2s 283ms/step - loss: 2.3051 - accuracy: 0.0938 - val_loss: 2.3000 - val_accuracy: 0.2000 - lr: 6.2500e-04\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 2s 306ms/step - loss: 2.3041 - accuracy: 0.0750 - val_loss: 2.3032 - val_accuracy: 0.0500 - lr: 6.2500e-04\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 2s 295ms/step - loss: 2.3027 - accuracy: 0.1187 - val_loss: 2.3033 - val_accuracy: 0.0500 - lr: 6.2500e-04\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 2s 264ms/step - loss: 2.3020 - accuracy: 0.1312 - val_loss: 2.3029 - val_accuracy: 0.1000 - lr: 6.2500e-04\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 2s 263ms/step - loss: 2.3034 - accuracy: 0.0938 - val_loss: 2.3031 - val_accuracy: 0.1500 - lr: 6.2500e-04\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 2s 292ms/step - loss: 2.3056 - accuracy: 0.0938 - val_loss: 2.3033 - val_accuracy: 0.1000 - lr: 6.2500e-04\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 2s 279ms/step - loss: 2.3029 - accuracy: 0.0688 - val_loss: 2.2982 - val_accuracy: 0.2500 - lr: 6.2500e-04\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 2s 388ms/step - loss: 2.3040 - accuracy: 0.0875 - val_loss: 2.3020 - val_accuracy: 0.0500 - lr: 6.2500e-04\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 2s 312ms/step - loss: 2.3023 - accuracy: 0.0938 - val_loss: 2.3018 - val_accuracy: 0.1000 - lr: 6.2500e-04\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 2s 403ms/step - loss: 2.3008 - accuracy: 0.1125 - val_loss: 2.3044 - val_accuracy: 0.0500 - lr: 6.2500e-04\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 2s 341ms/step - loss: 2.3024 - accuracy: 0.1312 - val_loss: 2.3040 - val_accuracy: 0.1000 - lr: 6.2500e-04\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 2.3047 - accuracy: 0.0812 - val_loss: 2.3028 - val_accuracy: 0.0500 - lr: 6.2500e-04\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 2s 417ms/step - loss: 2.3022 - accuracy: 0.0812 - val_loss: 2.3019 - val_accuracy: 0.0500 - lr: 6.2500e-04\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 2.3040 - accuracy: 0.1063 - val_loss: 2.3033 - val_accuracy: 0.0500 - lr: 6.2500e-04\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 2s 361ms/step - loss: 2.3023 - accuracy: 0.1187 - val_loss: 2.3044 - val_accuracy: 0.0000e+00 - lr: 6.2500e-04\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 2s 333ms/step - loss: 2.3029 - accuracy: 0.0875 - val_loss: 2.3021 - val_accuracy: 0.1500 - lr: 3.1250e-04\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 2.3007 - accuracy: 0.1187 - val_loss: 2.3000 - val_accuracy: 0.2000 - lr: 3.1250e-04\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 2s 307ms/step - loss: 2.3060 - accuracy: 0.1000 - val_loss: 2.3065 - val_accuracy: 0.0000e+00 - lr: 3.1250e-04\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 2s 344ms/step - loss: 2.3016 - accuracy: 0.1000 - val_loss: 2.3034 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 2s 298ms/step - loss: 2.3042 - accuracy: 0.0875 - val_loss: 2.3006 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 2s 345ms/step - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3044 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 2s 310ms/step - loss: 2.3016 - accuracy: 0.1187 - val_loss: 2.3043 - val_accuracy: 0.0500 - lr: 3.1250e-04\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 2s 325ms/step - loss: 2.3025 - accuracy: 0.1063 - val_loss: 2.3033 - val_accuracy: 0.0500 - lr: 3.1250e-04\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 2s 305ms/step - loss: 2.3023 - accuracy: 0.1312 - val_loss: 2.3026 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 2s 398ms/step - loss: 2.3019 - accuracy: 0.1500 - val_loss: 2.3032 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 2s 347ms/step - loss: 2.3034 - accuracy: 0.0750 - val_loss: 2.3012 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 2s 322ms/step - loss: 2.3040 - accuracy: 0.0562 - val_loss: 2.3019 - val_accuracy: 0.1500 - lr: 3.1250e-04\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 2s 292ms/step - loss: 2.3025 - accuracy: 0.1125 - val_loss: 2.3041 - val_accuracy: 0.0500 - lr: 3.1250e-04\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 2s 353ms/step - loss: 2.3043 - accuracy: 0.0625 - val_loss: 2.3017 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 2s 299ms/step - loss: 2.3042 - accuracy: 0.0750 - val_loss: 2.3026 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 2s 329ms/step - loss: 2.3039 - accuracy: 0.0812 - val_loss: 2.3010 - val_accuracy: 0.1500 - lr: 3.1250e-04\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 2s 299ms/step - loss: 2.3024 - accuracy: 0.0938 - val_loss: 2.3028 - val_accuracy: 0.0500 - lr: 3.1250e-04\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 2s 337ms/step - loss: 2.3030 - accuracy: 0.0938 - val_loss: 2.3031 - val_accuracy: 0.0000e+00 - lr: 3.1250e-04\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 2s 282ms/step - loss: 2.3026 - accuracy: 0.1312 - val_loss: 2.3035 - val_accuracy: 0.0500 - lr: 3.1250e-04\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 2s 325ms/step - loss: 2.3030 - accuracy: 0.1063 - val_loss: 2.3013 - val_accuracy: 0.1000 - lr: 3.1250e-04\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 2s 324ms/step - loss: 2.3042 - accuracy: 0.0875 - val_loss: 2.3035 - val_accuracy: 0.0500 - lr: 1.5625e-04\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 2s 331ms/step - loss: 2.3030 - accuracy: 0.0750 - val_loss: 2.3045 - val_accuracy: 0.0000e+00 - lr: 1.5625e-04\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 2s 298ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3006 - val_accuracy: 0.2500 - lr: 1.5625e-04\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 2s 285ms/step - loss: 2.3018 - accuracy: 0.1125 - val_loss: 2.3018 - val_accuracy: 0.1500 - lr: 1.5625e-04\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 2s 283ms/step - loss: 2.3040 - accuracy: 0.0812 - val_loss: 2.3012 - val_accuracy: 0.1500 - lr: 1.5625e-04\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 2s 286ms/step - loss: 2.3037 - accuracy: 0.0938 - val_loss: 2.2999 - val_accuracy: 0.1500 - lr: 1.5625e-04\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 2s 301ms/step - loss: 2.3029 - accuracy: 0.1125 - val_loss: 2.3034 - val_accuracy: 0.1000 - lr: 1.5625e-04\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 2s 318ms/step - loss: 2.3017 - accuracy: 0.0938 - val_loss: 2.3042 - val_accuracy: 0.0500 - lr: 1.5625e-04\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 2.3038 - accuracy: 0.0938 - val_loss: 2.3019 - val_accuracy: 0.1500 - lr: 1.5625e-04\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 2.3023 - accuracy: 0.1000 - val_loss: 2.3049 - val_accuracy: 0.1000 - lr: 1.5625e-04\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 2s 307ms/step - loss: 2.3015 - accuracy: 0.1187 - val_loss: 2.3012 - val_accuracy: 0.0500 - lr: 1.5625e-04\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 2s 395ms/step - loss: 2.3015 - accuracy: 0.1125 - val_loss: 2.3010 - val_accuracy: 0.1000 - lr: 1.5625e-04\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 2s 343ms/step - loss: 2.3000 - accuracy: 0.1375 - val_loss: 2.3040 - val_accuracy: 0.1000 - lr: 1.5625e-04\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 2s 324ms/step - loss: 2.3040 - accuracy: 0.0812 - val_loss: 2.3059 - val_accuracy: 0.0500 - lr: 1.5625e-04\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 2s 332ms/step - loss: 2.3044 - accuracy: 0.1063 - val_loss: 2.3011 - val_accuracy: 0.2000 - lr: 1.5625e-04\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 3s 401ms/step - loss: 2.3024 - accuracy: 0.0875 - val_loss: 2.3035 - val_accuracy: 0.0000e+00 - lr: 1.5625e-04\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 2s 318ms/step - loss: 2.3019 - accuracy: 0.0938 - val_loss: 2.3049 - val_accuracy: 0.1000 - lr: 1.5625e-04\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 3s 504ms/step - loss: 2.3015 - accuracy: 0.0938 - val_loss: 2.3020 - val_accuracy: 0.1000 - lr: 1.5625e-04\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 4s 639ms/step - loss: 2.3038 - accuracy: 0.0875 - val_loss: 2.3029 - val_accuracy: 0.1000 - lr: 1.5625e-04\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 2s 269ms/step - loss: 2.3020 - accuracy: 0.1125 - val_loss: 2.3058 - val_accuracy: 0.0500 - lr: 1.5625e-04\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 2s 277ms/step - loss: 2.3011 - accuracy: 0.1312 - val_loss: 2.2977 - val_accuracy: 0.3000 - lr: 7.8125e-05\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 2s 260ms/step - loss: 2.3032 - accuracy: 0.0812 - val_loss: 2.3019 - val_accuracy: 0.1500 - lr: 7.8125e-05\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 2s 261ms/step - loss: 2.3021 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.1000 - lr: 7.8125e-05\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 2s 262ms/step - loss: 2.3018 - accuracy: 0.1063 - val_loss: 2.3004 - val_accuracy: 0.1500 - lr: 7.8125e-05\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 2s 253ms/step - loss: 2.3018 - accuracy: 0.1187 - val_loss: 2.3020 - val_accuracy: 0.1000 - lr: 7.8125e-05\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 2s 256ms/step - loss: 2.3021 - accuracy: 0.0938 - val_loss: 2.3024 - val_accuracy: 0.1500 - lr: 7.8125e-05\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 2s 261ms/step - loss: 2.3039 - accuracy: 0.0812 - val_loss: 2.3053 - val_accuracy: 0.0000e+00 - lr: 7.8125e-05\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 2.2999 - accuracy: 0.1063 - val_loss: 2.3017 - val_accuracy: 0.2000 - lr: 7.8125e-05\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 2s 270ms/step - loss: 2.3024 - accuracy: 0.0750 - val_loss: 2.3061 - val_accuracy: 0.0500 - lr: 7.8125e-05\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 2.3013 - accuracy: 0.1250 - val_loss: 2.3032 - val_accuracy: 0.0500 - lr: 7.8125e-05\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 2.3024 - accuracy: 0.0875 - val_loss: 2.3041 - val_accuracy: 0.0000e+00 - lr: 7.8125e-05\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 2s 267ms/step - loss: 2.3020 - accuracy: 0.1187 - val_loss: 2.3035 - val_accuracy: 0.1000 - lr: 7.8125e-05\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 2s 251ms/step - loss: 2.3027 - accuracy: 0.1063 - val_loss: 2.3017 - val_accuracy: 0.1000 - lr: 7.8125e-05\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 2s 283ms/step - loss: 2.3046 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1500 - lr: 7.8125e-05\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 2s 273ms/step - loss: 2.3001 - accuracy: 0.1063 - val_loss: 2.3018 - val_accuracy: 0.1500 - lr: 7.8125e-05\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 3s 468ms/step - loss: 2.3019 - accuracy: 0.0688 - val_loss: 2.3008 - val_accuracy: 0.0500 - lr: 7.8125e-05\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 4s 538ms/step - loss: 2.3031 - accuracy: 0.0938 - val_loss: 2.3019 - val_accuracy: 0.0500 - lr: 7.8125e-05\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 3s 529ms/step - loss: 2.3039 - accuracy: 0.0750 - val_loss: 2.3026 - val_accuracy: 0.1500 - lr: 7.8125e-05\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 3s 397ms/step - loss: 2.3017 - accuracy: 0.1000 - val_loss: 2.3029 - val_accuracy: 0.0500 - lr: 7.8125e-05\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 3s 412ms/step - loss: 2.3033 - accuracy: 0.1312 - val_loss: 2.3019 - val_accuracy: 0.1500 - lr: 7.8125e-05\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 3s 435ms/step - loss: 2.3042 - accuracy: 0.0750 - val_loss: 2.3014 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 3s 664ms/step - loss: 2.3013 - accuracy: 0.1000 - val_loss: 2.3047 - val_accuracy: 0.0500 - lr: 3.9062e-05\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 2.3021 - accuracy: 0.1000 - val_loss: 2.3054 - val_accuracy: 0.0500 - lr: 3.9062e-05\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 2.3041 - accuracy: 0.1000 - val_loss: 2.2961 - val_accuracy: 0.3500 - lr: 3.9062e-05\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 3s 460ms/step - loss: 2.3044 - accuracy: 0.0688 - val_loss: 2.3016 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 2s 402ms/step - loss: 2.3028 - accuracy: 0.0938 - val_loss: 2.3026 - val_accuracy: 0.0500 - lr: 3.9062e-05\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 3s 467ms/step - loss: 2.3011 - accuracy: 0.1000 - val_loss: 2.3012 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 2.3024 - accuracy: 0.1063 - val_loss: 2.3004 - val_accuracy: 0.2000 - lr: 3.9062e-05\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 2s 354ms/step - loss: 2.3040 - accuracy: 0.1125 - val_loss: 2.3048 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 2s 261ms/step - loss: 2.3027 - accuracy: 0.0875 - val_loss: 2.3008 - val_accuracy: 0.1500 - lr: 3.9062e-05\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 2s 283ms/step - loss: 2.3002 - accuracy: 0.1187 - val_loss: 2.3019 - val_accuracy: 0.1500 - lr: 3.9062e-05\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 2.3028 - accuracy: 0.0875 - val_loss: 2.3038 - val_accuracy: 0.0500 - lr: 3.9062e-05\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 2s 283ms/step - loss: 2.3033 - accuracy: 0.1063 - val_loss: 2.3041 - val_accuracy: 0.1500 - lr: 3.9062e-05\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 2s 268ms/step - loss: 2.3016 - accuracy: 0.0875 - val_loss: 2.3022 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 2.3041 - accuracy: 0.0812 - val_loss: 2.3029 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 2s 271ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3048 - val_accuracy: 0.0500 - lr: 3.9062e-05\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 2s 253ms/step - loss: 2.3018 - accuracy: 0.1250 - val_loss: 2.3024 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 2s 251ms/step - loss: 2.3041 - accuracy: 0.0688 - val_loss: 2.3025 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 2s 268ms/step - loss: 2.3047 - accuracy: 0.0875 - val_loss: 2.3038 - val_accuracy: 0.1000 - lr: 3.9062e-05\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 2.3020 - accuracy: 0.1125 - val_loss: 2.3012 - val_accuracy: 0.1500 - lr: 3.9062e-05\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 2s 269ms/step - loss: 2.3018 - accuracy: 0.1000 - val_loss: 2.3006 - val_accuracy: 0.1500 - lr: 1.9531e-05\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 2s 276ms/step - loss: 2.3025 - accuracy: 0.0938 - val_loss: 2.3032 - val_accuracy: 0.0500 - lr: 1.9531e-05\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 2s 266ms/step - loss: 2.3033 - accuracy: 0.1250 - val_loss: 2.3035 - val_accuracy: 0.1500 - lr: 1.9531e-05\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 2s 269ms/step - loss: 2.3033 - accuracy: 0.1000 - val_loss: 2.3047 - val_accuracy: 0.0500 - lr: 1.9531e-05\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 2s 262ms/step - loss: 2.3031 - accuracy: 0.0875 - val_loss: 2.3039 - val_accuracy: 0.1000 - lr: 1.9531e-05\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 2s 259ms/step - loss: 2.3044 - accuracy: 0.1125 - val_loss: 2.3015 - val_accuracy: 0.1500 - lr: 1.9531e-05\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 2.3015 - accuracy: 0.1063 - val_loss: 2.2991 - val_accuracy: 0.2000 - lr: 1.9531e-05\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 2s 255ms/step - loss: 2.3028 - accuracy: 0.1562 - val_loss: 2.3046 - val_accuracy: 0.0500 - lr: 1.9531e-05\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 2s 274ms/step - loss: 2.3042 - accuracy: 0.0812 - val_loss: 2.3020 - val_accuracy: 0.1500 - lr: 1.9531e-05\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 2s 258ms/step - loss: 2.3018 - accuracy: 0.1187 - val_loss: 2.3027 - val_accuracy: 0.1000 - lr: 1.9531e-05\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 2s 261ms/step - loss: 2.3046 - accuracy: 0.0875 - val_loss: 2.3026 - val_accuracy: 0.1500 - lr: 1.9531e-05\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 2s 267ms/step - loss: 2.3021 - accuracy: 0.1125 - val_loss: 2.3032 - val_accuracy: 0.1000 - lr: 1.9531e-05\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.2998 - val_accuracy: 0.2000 - lr: 1.9531e-05\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 2s 256ms/step - loss: 2.3019 - accuracy: 0.1250 - val_loss: 2.3038 - val_accuracy: 0.1000 - lr: 1.9531e-05\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 2s 293ms/step - loss: 2.3023 - accuracy: 0.1125 - val_loss: 2.3015 - val_accuracy: 0.1500 - lr: 1.9531e-05\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 2s 317ms/step - loss: 2.3017 - accuracy: 0.1063 - val_loss: 2.3007 - val_accuracy: 0.1500 - lr: 1.9531e-05\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 2s 296ms/step - loss: 2.3013 - accuracy: 0.0750 - val_loss: 2.3024 - val_accuracy: 0.1000 - lr: 1.9531e-05\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 2s 290ms/step - loss: 2.3005 - accuracy: 0.1187 - val_loss: 2.3046 - val_accuracy: 0.0000e+00 - lr: 1.9531e-05\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 2s 289ms/step - loss: 2.3028 - accuracy: 0.0938 - val_loss: 2.3005 - val_accuracy: 0.2000 - lr: 1.9531e-05\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 2s 293ms/step - loss: 2.3037 - accuracy: 0.0938 - val_loss: 2.3046 - val_accuracy: 0.0500 - lr: 1.9531e-05\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 2s 349ms/step - loss: 2.3031 - accuracy: 0.1125 - val_loss: 2.3058 - val_accuracy: 0.0000e+00 - lr: 9.7656e-06\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 2s 293ms/step - loss: 2.3030 - accuracy: 0.0938 - val_loss: 2.3008 - val_accuracy: 0.1500 - lr: 9.7656e-06\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 2s 292ms/step - loss: 2.3023 - accuracy: 0.1063 - val_loss: 2.3004 - val_accuracy: 0.2000 - lr: 9.7656e-06\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 2s 275ms/step - loss: 2.3032 - accuracy: 0.0938 - val_loss: 2.3008 - val_accuracy: 0.1000 - lr: 9.7656e-06\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 2s 279ms/step - loss: 2.3021 - accuracy: 0.1187 - val_loss: 2.3026 - val_accuracy: 0.1000 - lr: 9.7656e-06\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 2s 251ms/step - loss: 2.3024 - accuracy: 0.1063 - val_loss: 2.3001 - val_accuracy: 0.1500 - lr: 9.7656e-06\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 2s 248ms/step - loss: 2.3024 - accuracy: 0.0938 - val_loss: 2.3040 - val_accuracy: 0.1000 - lr: 9.7656e-06\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 2s 252ms/step - loss: 2.3024 - accuracy: 0.1250 - val_loss: 2.2990 - val_accuracy: 0.1500 - lr: 9.7656e-06\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 2s 245ms/step - loss: 2.3040 - accuracy: 0.0750 - val_loss: 2.3027 - val_accuracy: 0.1500 - lr: 9.7656e-06\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 2.3046 - accuracy: 0.0500 - val_loss: 2.2993 - val_accuracy: 0.2000 - lr: 9.7656e-06\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 2.3019 - accuracy: 0.0812 - val_loss: 2.3049 - val_accuracy: 0.0000e+00 - lr: 9.7656e-06\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 2.3025 - accuracy: 0.1063 - val_loss: 2.2994 - val_accuracy: 0.2500 - lr: 9.7656e-06\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 2s 275ms/step - loss: 2.3019 - accuracy: 0.1187 - val_loss: 2.3017 - val_accuracy: 0.1000 - lr: 9.7656e-06\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 2s 251ms/step - loss: 2.3016 - accuracy: 0.1125 - val_loss: 2.3000 - val_accuracy: 0.2000 - lr: 9.7656e-06\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 2s 261ms/step - loss: 2.3030 - accuracy: 0.1063 - val_loss: 2.3050 - val_accuracy: 0.0500 - lr: 9.7656e-06\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 2s 257ms/step - loss: 2.3037 - accuracy: 0.0938 - val_loss: 2.3009 - val_accuracy: 0.2000 - lr: 9.7656e-06\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 2s 257ms/step - loss: 2.3026 - accuracy: 0.1063 - val_loss: 2.3037 - val_accuracy: 0.0500 - lr: 9.7656e-06\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 2s 257ms/step - loss: 2.3018 - accuracy: 0.0875 - val_loss: 2.3029 - val_accuracy: 0.0000e+00 - lr: 9.7656e-06\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 2.3024 - accuracy: 0.0812 - val_loss: 2.3045 - val_accuracy: 0.0500 - lr: 9.7656e-06\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 2s 261ms/step - loss: 2.3026 - accuracy: 0.0875 - val_loss: 2.3025 - val_accuracy: 0.1000 - lr: 9.7656e-06\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 2s 258ms/step - loss: 2.3020 - accuracy: 0.1000 - val_loss: 2.3036 - val_accuracy: 0.0500 - lr: 4.8828e-06\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 2s 248ms/step - loss: 2.3034 - accuracy: 0.0875 - val_loss: 2.2983 - val_accuracy: 0.2500 - lr: 4.8828e-06\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 2s 267ms/step - loss: 2.3039 - accuracy: 0.1000 - val_loss: 2.3009 - val_accuracy: 0.1000 - lr: 4.8828e-06\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 2.3022 - accuracy: 0.1312 - val_loss: 2.3050 - val_accuracy: 0.1000 - lr: 4.8828e-06\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 2s 259ms/step - loss: 2.3011 - accuracy: 0.1000 - val_loss: 2.2974 - val_accuracy: 0.2500 - lr: 4.8828e-06\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 2.3027 - accuracy: 0.1187 - val_loss: 2.3059 - val_accuracy: 0.0000e+00 - lr: 4.8828e-06\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 2s 246ms/step - loss: 2.3010 - accuracy: 0.1250 - val_loss: 2.2978 - val_accuracy: 0.3000 - lr: 4.8828e-06\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 2s 241ms/step - loss: 2.3028 - accuracy: 0.0938 - val_loss: 2.3001 - val_accuracy: 0.2000 - lr: 4.8828e-06\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 2s 258ms/step - loss: 2.3028 - accuracy: 0.1125 - val_loss: 2.3041 - val_accuracy: 0.1000 - lr: 4.8828e-06\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 2s 269ms/step - loss: 2.3023 - accuracy: 0.1187 - val_loss: 2.3028 - val_accuracy: 0.1500 - lr: 4.8828e-06\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 2.3029 - accuracy: 0.1000 - val_loss: 2.3053 - val_accuracy: 0.0000e+00 - lr: 4.8828e-06\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 2.3031 - accuracy: 0.0938 - val_loss: 2.3030 - val_accuracy: 0.0500 - lr: 4.8828e-06\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 2.3036 - accuracy: 0.0750 - val_loss: 2.3019 - val_accuracy: 0.1500 - lr: 4.8828e-06\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 2s 244ms/step - loss: 2.3027 - accuracy: 0.1312 - val_loss: 2.3059 - val_accuracy: 0.0500 - lr: 4.8828e-06\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 2.3029 - accuracy: 0.1000 - val_loss: 2.3039 - val_accuracy: 0.0000e+00 - lr: 4.8828e-06\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 2s 258ms/step - loss: 2.3029 - accuracy: 0.1125 - val_loss: 2.3025 - val_accuracy: 0.0500 - lr: 4.8828e-06\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 2.3024 - accuracy: 0.0938 - val_loss: 2.3034 - val_accuracy: 0.1000 - lr: 4.8828e-06\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 2.3032 - accuracy: 0.1125 - val_loss: 2.3011 - val_accuracy: 0.1500 - lr: 4.8828e-06\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 2.3029 - accuracy: 0.1125 - val_loss: 2.3021 - val_accuracy: 0.1500 - lr: 4.8828e-06\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 2.3026 - accuracy: 0.0875 - val_loss: 2.3017 - val_accuracy: 0.1500 - lr: 4.8828e-06\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 2.3038 - accuracy: 0.0938 - val_loss: 2.3026 - val_accuracy: 0.1500 - lr: 2.4414e-06\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 2s 292ms/step - loss: 2.3025 - accuracy: 0.1250 - val_loss: 2.3031 - val_accuracy: 0.0500 - lr: 2.4414e-06\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 2.3027 - accuracy: 0.0938 - val_loss: 2.2995 - val_accuracy: 0.1500 - lr: 2.4414e-06\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 2s 253ms/step - loss: 2.3021 - accuracy: 0.0875 - val_loss: 2.3035 - val_accuracy: 0.0500 - lr: 2.4414e-06\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 2s 289ms/step - loss: 2.3029 - accuracy: 0.0938 - val_loss: 2.3029 - val_accuracy: 0.0500 - lr: 2.4414e-06\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 2s 282ms/step - loss: 2.3015 - accuracy: 0.0750 - val_loss: 2.3037 - val_accuracy: 0.0500 - lr: 2.4414e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2040/474066307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwandb_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1202\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[0;32m   1203\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m           \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_recreate_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m           \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1201\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    724\u001b[0m             \u001b[1;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m             \"not be specified.\")\n\u001b[1;32m--> 726\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    749\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 751\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3234\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3235\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3236\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3237\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3238\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=config.epoch, callbacks=[lr_callback, wandb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('steven{}.h5'.format(TRIAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
