{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  tf.random.set_seed(seed)\n",
    "\n",
    "SEED = 22\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 132, 1536, 1599, 1662] 1662\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from itertools import accumulate\n",
    "\n",
    "landmark_lens = (\n",
    "    (33, 4),\n",
    "    (468, 3),\n",
    "    (21, 3),\n",
    "    (21, 3)\n",
    ")\n",
    "landmark_locs = list(accumulate(landmark_lens, lambda a, b: a + b[0]*b[1], initial=0))\n",
    "landmarks_len = reduce(lambda r, loc: r + loc[0] * loc[1], landmark_lens, 0)\n",
    "print(landmark_locs, landmarks_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = 'tracks_binary_manual'\n",
    "data_folder = 'tracks_binary'\n",
    "labels = [label for label in os.listdir(data_folder) if os.path.isdir(f'{data_folder}/{label}')]\n",
    "NUM_CLASSES = len(labels)\n",
    "\n",
    "labels_tensor = tf.constant(labels)\n",
    "ids_tensor = tf.constant(range(len(labels)))\n",
    "\n",
    "ids_from_labels = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        labels_tensor,\n",
    "        ids_tensor\n",
    "    ),\n",
    "    default_value=-1\n",
    ")\n",
    "\n",
    "labels_from_ids = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        ids_tensor,\n",
    "        labels_tensor\n",
    "    ),\n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "def to_categorical(label):\n",
    "    return tf.one_hot(\n",
    "        ids_from_labels.lookup(label),\n",
    "        depth=NUM_CLASSES\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_binary(file_path):\n",
    "    label = tf.strings.split(file_path, os.sep)[-2]\n",
    "\n",
    "    raw = tf.io.read_file(file_path)\n",
    "    data = tf.io.decode_raw(raw, tf.float32)\n",
    "    data = tf.reshape(data, [-1, landmarks_len])\n",
    "\n",
    "    pose = tf.reshape(data[:, 0:132], [-1, 33, 4])\n",
    "    # lh = tf.reshape(data[:, 132:195], [-1, 21, 3])\n",
    "    # rh = tf.reshape(data[:, 195:258], [-1, 21, 3])\n",
    "    \n",
    "    face = tf.reshape(data[:, 132:1536], [-1, 468, 3])\n",
    "    lh = tf.reshape(data[:, 1536:1599], [-1, 21, 3])\n",
    "    rh = tf.reshape(data[:, 1599:1662], [-1, 21, 3])\n",
    "\n",
    "    return (pose, lh, rh), to_categorical(label)\n",
    "    # return (pose, face, lh, rh), to_categorical(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import reduce_max, reduce_min\n",
    "\n",
    "FRAMES = 64\n",
    "\n",
    "def flatten(x):\n",
    "    pose = tf.reshape(x[0], shape=[-1, 132])\n",
    "    # face = tf.reshape(x[1], shape=[-1, 1404])\n",
    "    lh = tf.reshape(x[1], shape=[-1, 63])\n",
    "    rh = tf.reshape(x[2], shape=[-1, 63])\n",
    "    return tf.concat([pose, lh, rh], axis=1)\n",
    "\n",
    "\n",
    "def random_window(x):\n",
    "    def pad(x):\n",
    "        missing = FRAMES - size\n",
    "        start_pad = tf.math.ceil(missing / 2)\n",
    "        end_pad = tf.math.floor(missing / 2)\n",
    "        return tf.concat([\n",
    "            tf.tile([x[0]], [start_pad, 1]),\n",
    "            x,\n",
    "            tf.tile([x[-1]], [end_pad, 1])\n",
    "        ], axis=0)\n",
    "\n",
    "    def random_slice(x):\n",
    "        i = tf.random.uniform(shape=(), maxval=size+1-FRAMES, dtype=tf.int32)\n",
    "        return x[i: i+FRAMES]\n",
    "\n",
    "    size = tf.shape(x)[0]\n",
    "    print(size)\n",
    "    return tf.cond(\n",
    "        size < FRAMES,\n",
    "        lambda: pad(x),\n",
    "        lambda: random_slice(x)\n",
    "    )\n",
    "    \n",
    "def calc_bounding(pose, lh, rh):\n",
    "    max_x = reduce_max(tf.stack([reduce_max(pose[:, :, :1]), reduce_max(lh[:, :, :1]), reduce_max(rh[:, :, :1])], axis=0))\n",
    "    min_x = reduce_min(tf.stack([reduce_min(pose[:, :, :1]), reduce_min(lh[:, :, :1]), reduce_min(rh[:, :, :1])], axis=0))\n",
    "    \n",
    "    max_y = reduce_max(tf.stack([reduce_max(pose[:, :, 1:2]), reduce_max(lh[:, :, 1:2]), reduce_max(rh[:, :, 1:2])], axis=0))\n",
    "    min_y = reduce_min(tf.stack([reduce_min(pose[:, :, 1:2]), reduce_min(lh[:, :, 1:2]), reduce_min(rh[:, :, 1:2])], axis=0))\n",
    "\n",
    "    window = tf.cast((max_x - min_x, max_y - min_y), dtype=tf.float32)\n",
    "    mid = ((max_x + min_x)/2, (max_y + min_y)/2)\n",
    "    return (window, mid)\n",
    "\n",
    "def scale(x, factor):\n",
    "    pose, lh, rh = x[0], x[1], x[2]\n",
    "    window, mid = calc_bounding(pose, lh, rh)\n",
    "    scale = factor * window\n",
    "    pose_shape, lh_shape, rh_shape = tf.shape(pose), tf.shape(lh), tf.shape(rh)\n",
    "    pose_center = tf.tile([[[mid[0], mid[1], 0, 0]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    # face_center = tf.tile([[[mid[0], mid[1], 0]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_center = tf.tile([[[mid[0], mid[1], 0]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_center = tf.tile([[[mid[0], mid[1], 0]]], [rh_shape[0], rh_shape[1], 1])\n",
    "    \n",
    "    pose_scale = tf.tile([[[scale[0], scale[1], 1, 1]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    # face_scale = tf.tile([[[scale[0], scale[1], 1]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_scale = tf.tile([[[scale[0], scale[1], 1]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_scale = tf.tile([[[scale[0], scale[1], 1]]], [rh_shape[0], rh_shape[1], 1])\n",
    "    \n",
    "    scaled_pose = pose_center + (pose - pose_center) * pose_scale\n",
    "    # scaled_face = face_center + (face - face_center) * face_scale\n",
    "    scaled_lh = lh_center + (lh - lh_center) * lh_scale\n",
    "    scaled_rh = rh_center + (rh - rh_center) * rh_scale\n",
    "\n",
    "    return (scaled_pose, scaled_lh, scaled_rh)\n",
    "\n",
    "def random_translation(x):\n",
    "    pose, lh, rh = x[0], x[1], x[2]\n",
    "    magnitude = tf.random.uniform(shape=[2], minval=-0.25, maxval=0.25)\n",
    "    pose_shape, lh_shape, rh_shape = tf.shape(pose), tf.shape(lh), tf.shape(rh)\n",
    "    \n",
    "    pose_trans = tf.tile([[[magnitude[0], magnitude[1], 0, 0]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    # face_trans = tf.tile([[[magnitude[0], magnitude[1], 0]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_trans = tf.tile([[[magnitude[0], magnitude[1], 0]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_trans = tf.tile([[[magnitude[0], magnitude[1], 0]]], [rh_shape[0], rh_shape[1], 1])\n",
    "\n",
    "    return (pose+pose_trans, lh+lh_trans, rh+rh_trans)\n",
    "    \n",
    "def flip(x):\n",
    "    pose, lh, rh = x[0], x[1], x[2]\n",
    "    pose_shape, lh_shape, rh_shape = tf.shape(pose), tf.shape(lh), tf.shape(rh)\n",
    "    \n",
    "    pose_neg = tf.tile([[[-1.0, 1, 1, 1]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    # face_neg = tf.tile([[[-1.0, 1, 1]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_neg = tf.tile([[[-1.0, 1, 1]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_neg = tf.tile([[[-1.0, 1, 1]]], [rh_shape[0], rh_shape[1], 1])\n",
    "    \n",
    "    pose_trans = tf.tile([[[1.0, 0, 0, 0]]], [pose_shape[0], pose_shape[1], 1])\n",
    "    # face_trans = tf.tile([[[1.0, 0, 0]]], [face_shape[0], face_shape[1], 1])\n",
    "    lh_trans = tf.tile([[[1.0, 0, 0]]], [lh_shape[0], lh_shape[1], 1])\n",
    "    rh_trans = tf.tile([[[1.0, 0, 0]]], [rh_shape[0], rh_shape[1], 1])\n",
    "\n",
    "    flipped_pose = pose_trans + pose * pose_neg\n",
    "    # flipped_face = face_trans + face * face_neg\n",
    "    flipped_lh = lh_trans + lh * lh_neg\n",
    "    flipped_rh = rh_trans + rh * rh_neg\n",
    "    \n",
    "    return (flipped_pose, flipped_lh, flipped_rh)\n",
    "    \n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (random_translation(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.map(lambda x, y: (scale(x, 0.1), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.map(lambda x, y: (flip(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "               \n",
    "    ds = ds.map(lambda x, y: (flatten(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    ds = ds.map(lambda x, y: (random_window(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000, seed=SEED)\n",
    "        \n",
    "    ds = ds.batch(32)\n",
    "\n",
    "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_split(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=1000):\n",
    "  assert (train_split + test_split + val_split) == 1\n",
    "  \n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(shuffle_size, seed=SEED)\n",
    "  \n",
    "  train_size = int(train_split * ds_size)\n",
    "  val_size = int(val_split * ds_size)\n",
    "  \n",
    "  train_ds = ds.take(train_size)\n",
    "  val_ds = ds.skip(train_size).take(val_size)\n",
    "  test_ds = ds.skip(train_size).skip(val_size)\n",
    "  \n",
    "  return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (((None, 33, 4), (None, 21, 3), (None, 21, 3)), (10,)), types: ((tf.float32, tf.float32, tf.float32), tf.float32)>\n",
      "<TakeDataset shapes: (((None, 33, 4), (None, 21, 3), (None, 21, 3)), (10,)), types: ((tf.float32, tf.float32, tf.float32), tf.float32)>\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "ds = tf.data.Dataset.list_files(f'{data_folder}/*/*')\n",
    "ds = ds.map(process_binary)\n",
    "print(ds)\n",
    "train_ds, val_ds, test_ds = get_ds_split(ds, len(ds))\n",
    "print(train_ds)\n",
    "\n",
    "train_ds = prepare(train_ds, augment=False)\n",
    "val_ds = prepare(val_ds)\n",
    "test_ds = prepare(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None, 258), (None, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None, 258), (None, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 1 2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "from wandb.keras import WandbCallback\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2eslw63j) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9248... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7360185c2c408aae7ef1a18d145daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▁▁▁▂▂▂▂▃▃▄▄▄▄▅▅▆▆▆▇▇▇▇███▇▇███▇██████▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>███▇▇▇▇▇▇▆▆▆▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>████▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.81961</td></tr><tr><td>epoch</td><td>999</td></tr><tr><td>loss</td><td>0.51017</td></tr><tr><td>lr</td><td>0.0</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vague-totem-27</strong>: <a href=\"https://wandb.ai/richardsonqiu/bi-LSTM/runs/2eslw63j\" target=\"_blank\">https://wandb.ai/richardsonqiu/bi-LSTM/runs/2eslw63j</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211218_163252-2eslw63j\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2eslw63j). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/richardsonqiu/bi-LSTM/runs/3b29hrgw\" target=\"_blank\">faithful-paper-28</a></strong> to <a href=\"https://wandb.ai/richardsonqiu/bi-LSTM\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "  project=\"bi-LSTM\",\n",
    "  entity=\"richardsonqiu\", \n",
    "  config={\n",
    "    \"lstm_1\": 120,\n",
    "    \"layer_1\": 120,\n",
    "    \"act_1\": \"relu\",\n",
    "    \n",
    "    \"lstm_2\": 130,\n",
    "    # \"dropout_2\": 0.1,\n",
    "    \"layer_2\": 130,\n",
    "    \"act_2\": \"relu\",\n",
    "        \n",
    "    \"lstm_3\": 200,\n",
    "    \"dropout_3\": 0.2,\n",
    "    \n",
    "    \"last_layer\": NUM_CLASSES,\n",
    "    \"last_act\": \"softmax\",\n",
    "    \n",
    "    \"optimizer\": \"adam\",\n",
    "    \"init_lr\": 0.01,\n",
    "    \"loss\": \"categorical_crossentropy\",\n",
    "    \"metric\": \"accuracy\",\n",
    "    \"epoch\": 1000,\n",
    "    \"batch_size\": 32,\n",
    "    \"data\": \"default\",\n",
    "    \"landmarks\": \"pose, lh, rh\",\n",
    "    \"augment\": False  \n",
    "    })\n",
    "config = wandb.config\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(config.lstm_1, return_sequences=True), input_shape=(FRAMES, 258)))\n",
    "model.add(Dense(config.layer_1, activation=config.act_1))\n",
    "model.add(Bidirectional(LSTM(config.lstm_2, return_sequences=True)))\n",
    "model.add(Dense(config.layer_2, activation=config.act_2))\n",
    "model.add(Bidirectional(LSTM(config.lstm_3, return_sequences=False, dropout=config.dropout_3)))\n",
    "model.add(Dense(config.last_layer, activation=config.last_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=config.init_lr)\n",
    "model.compile(optimizer=opt, loss=config.loss, metrics=[config.metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_6 (Bidirectio  (None, 64, 240)          363840    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64, 120)           28920     \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 64, 260)          261040    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64, 130)           33930     \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 400)              529600    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                4010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,221,340\n",
      "Trainable params: 1,221,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "lr_callback = ReduceLROnPlateau(monitor='loss', patience=20, factor=0.5, min_lr=1e-6)\n",
    "wandb_callback = WandbCallback(log_evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is unable to log validation data. When using a generator for validation_data, you must pass validation_steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 20s 854ms/step - loss: 2.7403 - accuracy: 0.1216 - val_loss: 2.2972 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 3s 278ms/step - loss: 2.3167 - accuracy: 0.1020 - val_loss: 2.2354 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 2s 246ms/step - loss: 2.2538 - accuracy: 0.1176 - val_loss: 2.1582 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 2.2827 - accuracy: 0.1451 - val_loss: 2.2616 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 2.2538 - accuracy: 0.1373 - val_loss: 2.3572 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 2.2370 - accuracy: 0.1255 - val_loss: 2.2165 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.2165 - accuracy: 0.0980 - val_loss: 2.2946 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 2.2374 - accuracy: 0.1137 - val_loss: 2.1021 - val_accuracy: 0.0323 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 2.2341 - accuracy: 0.1216 - val_loss: 2.2674 - val_accuracy: 0.0323 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 2.2021 - accuracy: 0.1569 - val_loss: 2.2699 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 2.2143 - accuracy: 0.1373 - val_loss: 2.3735 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 2.2167 - accuracy: 0.1490 - val_loss: 2.2378 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2258 - accuracy: 0.1451 - val_loss: 2.1607 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2360 - accuracy: 0.1216 - val_loss: 2.1301 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.2278 - accuracy: 0.1412 - val_loss: 2.2696 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 2.2047 - accuracy: 0.1490 - val_loss: 2.1709 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 2.2200 - accuracy: 0.0902 - val_loss: 2.2910 - val_accuracy: 0.0323 - lr: 0.0100\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 2.2194 - accuracy: 0.1686 - val_loss: 2.2251 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 2.2210 - accuracy: 0.1294 - val_loss: 2.3257 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2163 - accuracy: 0.1569 - val_loss: 2.1491 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2181 - accuracy: 0.1412 - val_loss: 2.2261 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2018 - accuracy: 0.1294 - val_loss: 2.1877 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2267 - accuracy: 0.1098 - val_loss: 2.1820 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2101 - accuracy: 0.1020 - val_loss: 2.2321 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.2204 - accuracy: 0.0980 - val_loss: 2.1562 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 2.2207 - accuracy: 0.1373 - val_loss: 2.1438 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 2.2291 - accuracy: 0.1176 - val_loss: 2.1514 - val_accuracy: 0.2581 - lr: 0.0100\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 2.2047 - accuracy: 0.1059 - val_loss: 2.1575 - val_accuracy: 0.0323 - lr: 0.0100\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1933 - accuracy: 0.1569 - val_loss: 2.2075 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2164 - accuracy: 0.1333 - val_loss: 2.1400 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.2068 - accuracy: 0.1608 - val_loss: 2.1851 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2209 - accuracy: 0.1451 - val_loss: 2.1567 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 2.1977 - accuracy: 0.1490 - val_loss: 2.2301 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1981 - accuracy: 0.1373 - val_loss: 2.2280 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2152 - accuracy: 0.1294 - val_loss: 2.3516 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2092 - accuracy: 0.1294 - val_loss: 2.2515 - val_accuracy: 0.2258 - lr: 0.0100\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2328 - accuracy: 0.1412 - val_loss: 2.2260 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1985 - accuracy: 0.1294 - val_loss: 2.2270 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.1976 - accuracy: 0.1529 - val_loss: 2.1237 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 2.1892 - accuracy: 0.1490 - val_loss: 2.1431 - val_accuracy: 0.0323 - lr: 0.0100\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 2s 251ms/step - loss: 2.1946 - accuracy: 0.1294 - val_loss: 2.2829 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.1915 - accuracy: 0.1451 - val_loss: 2.2376 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2161 - accuracy: 0.1373 - val_loss: 2.1332 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.1972 - accuracy: 0.1412 - val_loss: 2.2212 - val_accuracy: 0.0323 - lr: 0.0100\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 2.1939 - accuracy: 0.1608 - val_loss: 2.2546 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1901 - accuracy: 0.1529 - val_loss: 2.3914 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2023 - accuracy: 0.1451 - val_loss: 2.2149 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 2.1877 - accuracy: 0.1255 - val_loss: 2.1145 - val_accuracy: 0.2903 - lr: 0.0100\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2077 - accuracy: 0.0980 - val_loss: 2.1641 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 2.1956 - accuracy: 0.1608 - val_loss: 2.1990 - val_accuracy: 0.2581 - lr: 0.0100\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 2.2182 - accuracy: 0.1529 - val_loss: 2.2312 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2086 - accuracy: 0.1490 - val_loss: 2.2011 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 2.2134 - accuracy: 0.1216 - val_loss: 2.3280 - val_accuracy: 0.0323 - lr: 0.0100\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2338 - accuracy: 0.1373 - val_loss: 2.1816 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2041 - accuracy: 0.1255 - val_loss: 2.1939 - val_accuracy: 0.0323 - lr: 0.0100\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1999 - accuracy: 0.1529 - val_loss: 2.2838 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 2.1997 - accuracy: 0.1529 - val_loss: 2.1126 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 2.1818 - accuracy: 0.1373 - val_loss: 2.2553 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.1929 - accuracy: 0.1373 - val_loss: 2.1247 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1894 - accuracy: 0.1412 - val_loss: 2.3004 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2238 - accuracy: 0.1059 - val_loss: 2.2840 - val_accuracy: 0.2581 - lr: 0.0100\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1894 - accuracy: 0.1490 - val_loss: 2.1223 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 2s 241ms/step - loss: 2.1809 - accuracy: 0.1216 - val_loss: 2.0457 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1963 - accuracy: 0.1569 - val_loss: 2.1453 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2037 - accuracy: 0.1412 - val_loss: 2.2573 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2016 - accuracy: 0.1647 - val_loss: 2.2222 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1965 - accuracy: 0.1373 - val_loss: 2.0525 - val_accuracy: 0.2581 - lr: 0.0100\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1949 - accuracy: 0.1608 - val_loss: 2.1921 - val_accuracy: 0.2903 - lr: 0.0100\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2002 - accuracy: 0.1569 - val_loss: 2.0905 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1879 - accuracy: 0.1608 - val_loss: 2.1089 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 2.2055 - accuracy: 0.1333 - val_loss: 2.1004 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.1964 - accuracy: 0.1137 - val_loss: 2.2379 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1915 - accuracy: 0.1490 - val_loss: 2.2031 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1868 - accuracy: 0.1333 - val_loss: 2.2767 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2165 - accuracy: 0.1451 - val_loss: 2.2125 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2123 - accuracy: 0.1529 - val_loss: 2.2236 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2236 - accuracy: 0.1216 - val_loss: 2.2037 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2183 - accuracy: 0.1294 - val_loss: 2.2178 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 2.2007 - accuracy: 0.1373 - val_loss: 2.2157 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1734 - accuracy: 0.1569 - val_loss: 2.1478 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2211 - accuracy: 0.1569 - val_loss: 2.1140 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2021 - accuracy: 0.1451 - val_loss: 2.2336 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2034 - accuracy: 0.1373 - val_loss: 2.1960 - val_accuracy: 0.2581 - lr: 0.0100\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1954 - accuracy: 0.1569 - val_loss: 2.1087 - val_accuracy: 0.2258 - lr: 0.0100\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.2045 - accuracy: 0.1294 - val_loss: 2.0217 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2066 - accuracy: 0.1373 - val_loss: 2.1828 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.2089 - accuracy: 0.0941 - val_loss: 2.2101 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.1928 - accuracy: 0.1451 - val_loss: 2.2254 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.2164 - accuracy: 0.1255 - val_loss: 2.2740 - val_accuracy: 0.2581 - lr: 0.0100\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2000 - accuracy: 0.0980 - val_loss: 2.1279 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1776 - accuracy: 0.1451 - val_loss: 2.1966 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1951 - accuracy: 0.1529 - val_loss: 2.1966 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1680 - accuracy: 0.1569 - val_loss: 2.1820 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2084 - accuracy: 0.1686 - val_loss: 2.2688 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1967 - accuracy: 0.1451 - val_loss: 2.3322 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1929 - accuracy: 0.1529 - val_loss: 2.1632 - val_accuracy: 0.2903 - lr: 0.0100\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2060 - accuracy: 0.1412 - val_loss: 2.1045 - val_accuracy: 0.2903 - lr: 0.0100\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2031 - accuracy: 0.1451 - val_loss: 2.2468 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1966 - accuracy: 0.1608 - val_loss: 2.1625 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1976 - accuracy: 0.1451 - val_loss: 2.0804 - val_accuracy: 0.2258 - lr: 0.0100\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2048 - accuracy: 0.1333 - val_loss: 2.1538 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1782 - accuracy: 0.1412 - val_loss: 2.2331 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2119 - accuracy: 0.1294 - val_loss: 2.1790 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1970 - accuracy: 0.1608 - val_loss: 2.1733 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2159 - accuracy: 0.1490 - val_loss: 2.2232 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2074 - accuracy: 0.1490 - val_loss: 2.2648 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.1599 - accuracy: 0.1451 - val_loss: 2.3056 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2004 - accuracy: 0.1647 - val_loss: 2.0996 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1951 - accuracy: 0.1412 - val_loss: 2.1984 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2096 - accuracy: 0.1255 - val_loss: 2.1938 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1987 - accuracy: 0.1529 - val_loss: 2.2289 - val_accuracy: 0.0968 - lr: 0.0100\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2006 - accuracy: 0.1529 - val_loss: 2.3147 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.2287 - accuracy: 0.1294 - val_loss: 2.1490 - val_accuracy: 0.0645 - lr: 0.0100\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2210 - accuracy: 0.1333 - val_loss: 2.2375 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2021 - accuracy: 0.1294 - val_loss: 2.1826 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1981 - accuracy: 0.1373 - val_loss: 2.1907 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1923 - accuracy: 0.1176 - val_loss: 2.3154 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2319 - accuracy: 0.1373 - val_loss: 2.3187 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2015 - accuracy: 0.1451 - val_loss: 2.1386 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1706 - accuracy: 0.1686 - val_loss: 2.1419 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1940 - accuracy: 0.1294 - val_loss: 2.1869 - val_accuracy: 0.2258 - lr: 0.0100\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2055 - accuracy: 0.1294 - val_loss: 2.2112 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1949 - accuracy: 0.1451 - val_loss: 2.1947 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1991 - accuracy: 0.1333 - val_loss: 2.1767 - val_accuracy: 0.1290 - lr: 0.0100\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1958 - accuracy: 0.1373 - val_loss: 2.1337 - val_accuracy: 0.1613 - lr: 0.0100\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1933 - accuracy: 0.1529 - val_loss: 2.2152 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 2.2070 - accuracy: 0.1255 - val_loss: 2.2294 - val_accuracy: 0.1935 - lr: 0.0100\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1975 - accuracy: 0.1490 - val_loss: 2.2203 - val_accuracy: 0.1935 - lr: 0.0050\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1991 - accuracy: 0.1490 - val_loss: 2.1951 - val_accuracy: 0.1290 - lr: 0.0050\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1942 - accuracy: 0.1412 - val_loss: 2.1542 - val_accuracy: 0.0968 - lr: 0.0050\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1822 - accuracy: 0.1451 - val_loss: 2.2627 - val_accuracy: 0.0323 - lr: 0.0050\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.1797 - accuracy: 0.1686 - val_loss: 2.2494 - val_accuracy: 0.0645 - lr: 0.0050\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2076 - accuracy: 0.1373 - val_loss: 2.3384 - val_accuracy: 0.1290 - lr: 0.0050\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2047 - accuracy: 0.1294 - val_loss: 2.4478 - val_accuracy: 0.0645 - lr: 0.0050\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1850 - accuracy: 0.1176 - val_loss: 2.1793 - val_accuracy: 0.1613 - lr: 0.0050\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.2180 - accuracy: 0.1333 - val_loss: 2.1025 - val_accuracy: 0.1613 - lr: 0.0050\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2099 - accuracy: 0.1294 - val_loss: 2.3422 - val_accuracy: 0.1290 - lr: 0.0050\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2108 - accuracy: 0.1451 - val_loss: 2.2628 - val_accuracy: 0.1613 - lr: 0.0050\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2097 - accuracy: 0.1529 - val_loss: 2.0568 - val_accuracy: 0.1290 - lr: 0.0050\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1974 - accuracy: 0.1686 - val_loss: 2.1363 - val_accuracy: 0.1290 - lr: 0.0050\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2217 - accuracy: 0.1333 - val_loss: 2.2524 - val_accuracy: 0.1613 - lr: 0.0050\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2087 - accuracy: 0.1412 - val_loss: 2.2057 - val_accuracy: 0.0968 - lr: 0.0050\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 2.1844 - accuracy: 0.1608 - val_loss: 2.1639 - val_accuracy: 0.1613 - lr: 0.0050\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 2.1978 - accuracy: 0.1412 - val_loss: 2.1546 - val_accuracy: 0.1290 - lr: 0.0050\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2147 - accuracy: 0.1569 - val_loss: 2.1572 - val_accuracy: 0.0968 - lr: 0.0050\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1965 - accuracy: 0.1608 - val_loss: 2.3337 - val_accuracy: 0.1613 - lr: 0.0050\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2067 - accuracy: 0.1294 - val_loss: 2.2352 - val_accuracy: 0.1290 - lr: 0.0050\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1897 - accuracy: 0.1529 - val_loss: 2.2999 - val_accuracy: 0.1290 - lr: 0.0025\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2083 - accuracy: 0.1451 - val_loss: 2.1403 - val_accuracy: 0.1613 - lr: 0.0025\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2003 - accuracy: 0.1490 - val_loss: 2.2444 - val_accuracy: 0.1613 - lr: 0.0025\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1937 - accuracy: 0.1451 - val_loss: 2.1662 - val_accuracy: 0.0968 - lr: 0.0025\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1943 - accuracy: 0.1216 - val_loss: 2.1491 - val_accuracy: 0.1613 - lr: 0.0025\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 2.1798 - accuracy: 0.1529 - val_loss: 2.1054 - val_accuracy: 0.1613 - lr: 0.0025\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1992 - accuracy: 0.1373 - val_loss: 2.2663 - val_accuracy: 0.1290 - lr: 0.0025\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1953 - accuracy: 0.1373 - val_loss: 2.1181 - val_accuracy: 0.0968 - lr: 0.0025\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2115 - accuracy: 0.1529 - val_loss: 2.1624 - val_accuracy: 0.0968 - lr: 0.0025\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2006 - accuracy: 0.1490 - val_loss: 2.1402 - val_accuracy: 0.1613 - lr: 0.0025\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.2148 - accuracy: 0.1451 - val_loss: 2.2507 - val_accuracy: 0.0645 - lr: 0.0025\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1962 - accuracy: 0.1451 - val_loss: 2.1777 - val_accuracy: 0.0645 - lr: 0.0025\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2018 - accuracy: 0.1490 - val_loss: 2.2228 - val_accuracy: 0.0645 - lr: 0.0025\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2026 - accuracy: 0.1373 - val_loss: 2.1893 - val_accuracy: 0.1290 - lr: 0.0025\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1978 - accuracy: 0.1490 - val_loss: 2.2280 - val_accuracy: 0.1935 - lr: 0.0025\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1936 - accuracy: 0.1529 - val_loss: 2.2851 - val_accuracy: 0.0968 - lr: 0.0025\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2086 - accuracy: 0.1529 - val_loss: 2.1351 - val_accuracy: 0.2581 - lr: 0.0025\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1925 - accuracy: 0.1490 - val_loss: 2.1782 - val_accuracy: 0.1935 - lr: 0.0025\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1921 - accuracy: 0.1529 - val_loss: 2.1123 - val_accuracy: 0.2581 - lr: 0.0025\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1976 - accuracy: 0.1333 - val_loss: 2.2090 - val_accuracy: 0.1613 - lr: 0.0025\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1950 - accuracy: 0.1255 - val_loss: 2.1956 - val_accuracy: 0.1613 - lr: 0.0012\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1802 - accuracy: 0.1608 - val_loss: 2.1107 - val_accuracy: 0.2258 - lr: 0.0012\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1911 - accuracy: 0.1412 - val_loss: 2.2986 - val_accuracy: 0.1290 - lr: 0.0012\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2008 - accuracy: 0.1412 - val_loss: 2.2767 - val_accuracy: 0.1613 - lr: 0.0012\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1903 - accuracy: 0.1529 - val_loss: 2.1736 - val_accuracy: 0.1613 - lr: 0.0012\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1889 - accuracy: 0.1608 - val_loss: 2.2172 - val_accuracy: 0.0323 - lr: 0.0012\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2094 - accuracy: 0.1569 - val_loss: 2.1000 - val_accuracy: 0.2581 - lr: 0.0012\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.1941 - accuracy: 0.1451 - val_loss: 2.1790 - val_accuracy: 0.2258 - lr: 0.0012\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1903 - accuracy: 0.1569 - val_loss: 2.2692 - val_accuracy: 0.1613 - lr: 0.0012\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2059 - accuracy: 0.1529 - val_loss: 2.2368 - val_accuracy: 0.0968 - lr: 0.0012\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2134 - accuracy: 0.1686 - val_loss: 2.3221 - val_accuracy: 0.2581 - lr: 0.0012\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1992 - accuracy: 0.1412 - val_loss: 2.1363 - val_accuracy: 0.1290 - lr: 0.0012\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.2054 - accuracy: 0.1333 - val_loss: 2.1325 - val_accuracy: 0.0645 - lr: 0.0012\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1754 - accuracy: 0.1373 - val_loss: 2.1802 - val_accuracy: 0.2258 - lr: 0.0012\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1679 - accuracy: 0.1333 - val_loss: 2.2151 - val_accuracy: 0.1613 - lr: 0.0012\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1894 - accuracy: 0.1569 - val_loss: 2.2614 - val_accuracy: 0.1290 - lr: 0.0012\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1944 - accuracy: 0.1412 - val_loss: 2.2537 - val_accuracy: 0.0645 - lr: 0.0012\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1956 - accuracy: 0.1490 - val_loss: 2.1117 - val_accuracy: 0.1290 - lr: 0.0012\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1934 - accuracy: 0.1412 - val_loss: 2.2316 - val_accuracy: 0.1290 - lr: 0.0012\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2243 - accuracy: 0.1294 - val_loss: 2.2204 - val_accuracy: 0.1613 - lr: 0.0012\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2039 - accuracy: 0.1451 - val_loss: 2.2199 - val_accuracy: 0.2581 - lr: 6.2500e-04\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2082 - accuracy: 0.1373 - val_loss: 2.2365 - val_accuracy: 0.0968 - lr: 6.2500e-04\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2000 - accuracy: 0.1490 - val_loss: 2.2057 - val_accuracy: 0.0968 - lr: 6.2500e-04\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1942 - accuracy: 0.1216 - val_loss: 2.1731 - val_accuracy: 0.0645 - lr: 6.2500e-04\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2033 - accuracy: 0.1725 - val_loss: 2.2839 - val_accuracy: 0.0968 - lr: 6.2500e-04\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2105 - accuracy: 0.1333 - val_loss: 2.0367 - val_accuracy: 0.2903 - lr: 6.2500e-04\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 2.1976 - accuracy: 0.1451 - val_loss: 2.0182 - val_accuracy: 0.2903 - lr: 6.2500e-04\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1749 - accuracy: 0.1529 - val_loss: 2.1750 - val_accuracy: 0.1935 - lr: 6.2500e-04\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2011 - accuracy: 0.1529 - val_loss: 2.2810 - val_accuracy: 0.0968 - lr: 6.2500e-04\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1981 - accuracy: 0.1373 - val_loss: 2.1636 - val_accuracy: 0.1613 - lr: 6.2500e-04\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.1938 - accuracy: 0.1529 - val_loss: 2.1957 - val_accuracy: 0.1935 - lr: 6.2500e-04\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2046 - accuracy: 0.1451 - val_loss: 2.1670 - val_accuracy: 0.1935 - lr: 6.2500e-04\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1981 - accuracy: 0.1451 - val_loss: 2.1703 - val_accuracy: 0.0968 - lr: 6.2500e-04\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2152 - accuracy: 0.1255 - val_loss: 2.2534 - val_accuracy: 0.2258 - lr: 6.2500e-04\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 2.1971 - accuracy: 0.1333 - val_loss: 2.2813 - val_accuracy: 0.2903 - lr: 6.2500e-04\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1833 - accuracy: 0.1529 - val_loss: 2.1147 - val_accuracy: 0.3226 - lr: 6.2500e-04\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1789 - accuracy: 0.1608 - val_loss: 2.2373 - val_accuracy: 0.0968 - lr: 6.2500e-04\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1906 - accuracy: 0.1529 - val_loss: 2.2620 - val_accuracy: 0.2258 - lr: 6.2500e-04\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 2.1898 - accuracy: 0.1451 - val_loss: 2.2241 - val_accuracy: 0.0645 - lr: 6.2500e-04\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2042 - accuracy: 0.1451 - val_loss: 2.1852 - val_accuracy: 0.1290 - lr: 6.2500e-04\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.1757 - accuracy: 0.1529 - val_loss: 2.1968 - val_accuracy: 0.1290 - lr: 3.1250e-04\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2062 - accuracy: 0.1373 - val_loss: 2.2190 - val_accuracy: 0.2258 - lr: 3.1250e-04\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2295 - accuracy: 0.1333 - val_loss: 2.2715 - val_accuracy: 0.0968 - lr: 3.1250e-04\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 2.1860 - accuracy: 0.1490 - val_loss: 2.2874 - val_accuracy: 0.0645 - lr: 3.1250e-04\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2032 - accuracy: 0.1490 - val_loss: 2.3507 - val_accuracy: 0.1290 - lr: 3.1250e-04\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1944 - accuracy: 0.1412 - val_loss: 2.2617 - val_accuracy: 0.0645 - lr: 3.1250e-04\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.2050 - accuracy: 0.1451 - val_loss: 2.1595 - val_accuracy: 0.0645 - lr: 3.1250e-04\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1832 - accuracy: 0.1490 - val_loss: 2.1994 - val_accuracy: 0.1613 - lr: 3.1250e-04\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 2.1860 - accuracy: 0.1373 - val_loss: 2.0876 - val_accuracy: 0.2581 - lr: 3.1250e-04\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1995 - accuracy: 0.1412 - val_loss: 2.2265 - val_accuracy: 0.1935 - lr: 3.1250e-04\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 2.1826 - accuracy: 0.1373 - val_loss: 2.1186 - val_accuracy: 0.1290 - lr: 3.1250e-04\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2019 - accuracy: 0.1255 - val_loss: 2.2031 - val_accuracy: 0.0968 - lr: 3.1250e-04\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1976 - accuracy: 0.1490 - val_loss: 2.1328 - val_accuracy: 0.1613 - lr: 3.1250e-04\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.1918 - accuracy: 0.1569 - val_loss: 2.2117 - val_accuracy: 0.0968 - lr: 3.1250e-04\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1754 - accuracy: 0.1569 - val_loss: 2.1208 - val_accuracy: 0.1935 - lr: 3.1250e-04\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1868 - accuracy: 0.1412 - val_loss: 2.2380 - val_accuracy: 0.1613 - lr: 3.1250e-04\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 2.1859 - accuracy: 0.1412 - val_loss: 2.2225 - val_accuracy: 0.1613 - lr: 3.1250e-04\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2034 - accuracy: 0.1490 - val_loss: 2.0409 - val_accuracy: 0.2258 - lr: 3.1250e-04\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1844 - accuracy: 0.1294 - val_loss: 2.1404 - val_accuracy: 0.1935 - lr: 3.1250e-04\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1893 - accuracy: 0.1373 - val_loss: 2.1298 - val_accuracy: 0.2581 - lr: 3.1250e-04\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1745 - accuracy: 0.1490 - val_loss: 2.2303 - val_accuracy: 0.1290 - lr: 1.5625e-04\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1910 - accuracy: 0.1451 - val_loss: 2.1400 - val_accuracy: 0.0968 - lr: 1.5625e-04\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1902 - accuracy: 0.1647 - val_loss: 2.0939 - val_accuracy: 0.2903 - lr: 1.5625e-04\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1971 - accuracy: 0.1451 - val_loss: 2.1283 - val_accuracy: 0.1613 - lr: 1.5625e-04\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1902 - accuracy: 0.1569 - val_loss: 2.0509 - val_accuracy: 0.2581 - lr: 1.5625e-04\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1893 - accuracy: 0.1529 - val_loss: 2.1399 - val_accuracy: 0.1935 - lr: 1.5625e-04\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2058 - accuracy: 0.1412 - val_loss: 2.2395 - val_accuracy: 0.1290 - lr: 1.5625e-04\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2163 - accuracy: 0.1490 - val_loss: 2.2169 - val_accuracy: 0.1935 - lr: 1.5625e-04\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2078 - accuracy: 0.1451 - val_loss: 2.1777 - val_accuracy: 0.0968 - lr: 1.5625e-04\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2053 - accuracy: 0.1529 - val_loss: 2.1921 - val_accuracy: 0.1290 - lr: 1.5625e-04\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2027 - accuracy: 0.1569 - val_loss: 2.2461 - val_accuracy: 0.0645 - lr: 1.5625e-04\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2105 - accuracy: 0.1373 - val_loss: 2.2214 - val_accuracy: 0.1290 - lr: 1.5625e-04\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.1908 - accuracy: 0.1333 - val_loss: 2.3082 - val_accuracy: 0.1935 - lr: 1.5625e-04\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1980 - accuracy: 0.1569 - val_loss: 2.1981 - val_accuracy: 0.3226 - lr: 1.5625e-04\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1830 - accuracy: 0.1490 - val_loss: 2.2362 - val_accuracy: 0.0968 - lr: 1.5625e-04\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 2.1988 - accuracy: 0.1451 - val_loss: 2.2544 - val_accuracy: 0.0968 - lr: 1.5625e-04\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1959 - accuracy: 0.1490 - val_loss: 2.1777 - val_accuracy: 0.1613 - lr: 1.5625e-04\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 2.1928 - accuracy: 0.1451 - val_loss: 2.1545 - val_accuracy: 0.1935 - lr: 1.5625e-04\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1960 - accuracy: 0.1569 - val_loss: 2.3065 - val_accuracy: 0.2258 - lr: 1.5625e-04\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.1944 - accuracy: 0.1412 - val_loss: 2.2670 - val_accuracy: 0.0645 - lr: 1.5625e-04\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 2.1829 - accuracy: 0.1608 - val_loss: 2.1286 - val_accuracy: 0.0323 - lr: 7.8125e-05\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2104 - accuracy: 0.1490 - val_loss: 2.1948 - val_accuracy: 0.0968 - lr: 7.8125e-05\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 2.2071 - accuracy: 0.1490 - val_loss: 2.2825 - val_accuracy: 0.1613 - lr: 7.8125e-05\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2022 - accuracy: 0.1373 - val_loss: 2.0642 - val_accuracy: 0.1290 - lr: 7.8125e-05\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2107 - accuracy: 0.1412 - val_loss: 2.2333 - val_accuracy: 0.0968 - lr: 7.8125e-05\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2110 - accuracy: 0.1490 - val_loss: 2.1788 - val_accuracy: 0.1935 - lr: 7.8125e-05\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2103 - accuracy: 0.1176 - val_loss: 2.2861 - val_accuracy: 0.1290 - lr: 7.8125e-05\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1960 - accuracy: 0.1333 - val_loss: 2.1589 - val_accuracy: 0.0323 - lr: 7.8125e-05\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1999 - accuracy: 0.1569 - val_loss: 2.1478 - val_accuracy: 0.0968 - lr: 7.8125e-05\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1675 - accuracy: 0.1647 - val_loss: 2.2233 - val_accuracy: 0.1935 - lr: 7.8125e-05\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2011 - accuracy: 0.1490 - val_loss: 2.2363 - val_accuracy: 0.1290 - lr: 7.8125e-05\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.1843 - accuracy: 0.1569 - val_loss: 2.2163 - val_accuracy: 0.1290 - lr: 7.8125e-05\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1972 - accuracy: 0.1451 - val_loss: 2.2788 - val_accuracy: 0.1290 - lr: 7.8125e-05\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.1821 - accuracy: 0.1529 - val_loss: 2.2086 - val_accuracy: 0.1290 - lr: 7.8125e-05\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.1991 - accuracy: 0.1529 - val_loss: 2.3139 - val_accuracy: 0.1935 - lr: 7.8125e-05\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2037 - accuracy: 0.1569 - val_loss: 2.3235 - val_accuracy: 0.0968 - lr: 7.8125e-05\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1989 - accuracy: 0.1490 - val_loss: 2.2214 - val_accuracy: 0.1613 - lr: 7.8125e-05\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2026 - accuracy: 0.1490 - val_loss: 2.1486 - val_accuracy: 0.1613 - lr: 7.8125e-05\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2170 - accuracy: 0.1294 - val_loss: 2.1057 - val_accuracy: 0.2258 - lr: 7.8125e-05\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2143 - accuracy: 0.1529 - val_loss: 2.1557 - val_accuracy: 0.2581 - lr: 7.8125e-05\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1900 - accuracy: 0.1451 - val_loss: 2.1365 - val_accuracy: 0.1935 - lr: 3.9062e-05\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1974 - accuracy: 0.1451 - val_loss: 2.2056 - val_accuracy: 0.1290 - lr: 3.9062e-05\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 2.2133 - accuracy: 0.1333 - val_loss: 2.1315 - val_accuracy: 0.0968 - lr: 3.9062e-05\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1877 - accuracy: 0.1451 - val_loss: 2.0835 - val_accuracy: 0.1290 - lr: 3.9062e-05\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2000 - accuracy: 0.1647 - val_loss: 2.2175 - val_accuracy: 0.2581 - lr: 3.9062e-05\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.1943 - accuracy: 0.1608 - val_loss: 2.2217 - val_accuracy: 0.2258 - lr: 3.9062e-05\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1807 - accuracy: 0.1608 - val_loss: 2.1733 - val_accuracy: 0.1935 - lr: 3.9062e-05\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1956 - accuracy: 0.1569 - val_loss: 2.2729 - val_accuracy: 0.1290 - lr: 3.9062e-05\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.2031 - accuracy: 0.1490 - val_loss: 2.3317 - val_accuracy: 0.0968 - lr: 3.9062e-05\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1974 - accuracy: 0.1373 - val_loss: 2.0940 - val_accuracy: 0.0968 - lr: 3.9062e-05\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2169 - accuracy: 0.1333 - val_loss: 2.1182 - val_accuracy: 0.1290 - lr: 3.9062e-05\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2080 - accuracy: 0.1451 - val_loss: 2.1894 - val_accuracy: 0.0968 - lr: 3.9062e-05\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2067 - accuracy: 0.1451 - val_loss: 2.0783 - val_accuracy: 0.1613 - lr: 3.9062e-05\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.2023 - accuracy: 0.1451 - val_loss: 2.2053 - val_accuracy: 0.1613 - lr: 3.9062e-05\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 2.2004 - accuracy: 0.1569 - val_loss: 2.1046 - val_accuracy: 0.1613 - lr: 3.9062e-05\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1946 - accuracy: 0.1451 - val_loss: 2.1683 - val_accuracy: 0.1290 - lr: 3.9062e-05\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1989 - accuracy: 0.1490 - val_loss: 2.1895 - val_accuracy: 0.2258 - lr: 3.9062e-05\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2021 - accuracy: 0.1490 - val_loss: 2.1721 - val_accuracy: 0.1290 - lr: 3.9062e-05\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1973 - accuracy: 0.1608 - val_loss: 2.2367 - val_accuracy: 0.1613 - lr: 3.9062e-05\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2069 - accuracy: 0.1569 - val_loss: 2.0894 - val_accuracy: 0.1290 - lr: 3.9062e-05\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2116 - accuracy: 0.1490 - val_loss: 2.2656 - val_accuracy: 0.1613 - lr: 1.9531e-05\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.1961 - accuracy: 0.1490 - val_loss: 2.1528 - val_accuracy: 0.1290 - lr: 1.9531e-05\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1894 - accuracy: 0.1490 - val_loss: 2.1510 - val_accuracy: 0.1290 - lr: 1.9531e-05\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1735 - accuracy: 0.1569 - val_loss: 2.1514 - val_accuracy: 0.1613 - lr: 1.9531e-05\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1977 - accuracy: 0.1451 - val_loss: 2.2708 - val_accuracy: 0.0968 - lr: 1.9531e-05\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.1734 - accuracy: 0.1686 - val_loss: 2.1226 - val_accuracy: 0.1290 - lr: 1.9531e-05\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2081 - accuracy: 0.1255 - val_loss: 2.2601 - val_accuracy: 0.1613 - lr: 1.9531e-05\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1942 - accuracy: 0.1608 - val_loss: 2.1489 - val_accuracy: 0.1935 - lr: 1.9531e-05\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1743 - accuracy: 0.1333 - val_loss: 2.1462 - val_accuracy: 0.0968 - lr: 1.9531e-05\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.1948 - accuracy: 0.1647 - val_loss: 2.1785 - val_accuracy: 0.0968 - lr: 1.9531e-05\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2030 - accuracy: 0.1569 - val_loss: 2.1529 - val_accuracy: 0.0323 - lr: 1.9531e-05\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1806 - accuracy: 0.1451 - val_loss: 2.1617 - val_accuracy: 0.1935 - lr: 1.9531e-05\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 2.2003 - accuracy: 0.1529 - val_loss: 2.1718 - val_accuracy: 0.1935 - lr: 1.9531e-05\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2122 - accuracy: 0.1451 - val_loss: 2.1784 - val_accuracy: 0.0968 - lr: 1.9531e-05\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2060 - accuracy: 0.1490 - val_loss: 2.2480 - val_accuracy: 0.1935 - lr: 1.9531e-05\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2041 - accuracy: 0.1412 - val_loss: 2.2176 - val_accuracy: 0.2258 - lr: 1.9531e-05\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1834 - accuracy: 0.1529 - val_loss: 2.2273 - val_accuracy: 0.2258 - lr: 1.9531e-05\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 2.1820 - accuracy: 0.1608 - val_loss: 2.1531 - val_accuracy: 0.1613 - lr: 1.9531e-05\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1618 - accuracy: 0.1490 - val_loss: 2.2722 - val_accuracy: 0.1935 - lr: 1.9531e-05\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1996 - accuracy: 0.1490 - val_loss: 2.1785 - val_accuracy: 0.1935 - lr: 1.9531e-05\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1849 - accuracy: 0.1490 - val_loss: 2.1501 - val_accuracy: 0.0645 - lr: 9.7656e-06\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2066 - accuracy: 0.1412 - val_loss: 2.3107 - val_accuracy: 0.1290 - lr: 9.7656e-06\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2028 - accuracy: 0.1412 - val_loss: 2.0479 - val_accuracy: 0.2258 - lr: 9.7656e-06\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1970 - accuracy: 0.1490 - val_loss: 2.1789 - val_accuracy: 0.1290 - lr: 9.7656e-06\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2184 - accuracy: 0.1412 - val_loss: 2.1145 - val_accuracy: 0.0968 - lr: 9.7656e-06\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1913 - accuracy: 0.1608 - val_loss: 2.1973 - val_accuracy: 0.0968 - lr: 9.7656e-06\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2015 - accuracy: 0.1490 - val_loss: 2.1752 - val_accuracy: 0.1290 - lr: 9.7656e-06\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2100 - accuracy: 0.1490 - val_loss: 2.2254 - val_accuracy: 0.0645 - lr: 9.7656e-06\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2048 - accuracy: 0.1451 - val_loss: 2.2426 - val_accuracy: 0.0968 - lr: 9.7656e-06\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2141 - accuracy: 0.1451 - val_loss: 2.1737 - val_accuracy: 0.1613 - lr: 9.7656e-06\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 2.2088 - accuracy: 0.1412 - val_loss: 2.1628 - val_accuracy: 0.0968 - lr: 9.7656e-06\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1828 - accuracy: 0.1451 - val_loss: 2.3557 - val_accuracy: 0.1613 - lr: 9.7656e-06\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.1805 - accuracy: 0.1490 - val_loss: 2.2093 - val_accuracy: 0.0968 - lr: 9.7656e-06\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1974 - accuracy: 0.1451 - val_loss: 2.1497 - val_accuracy: 0.0968 - lr: 9.7656e-06\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2000 - accuracy: 0.1412 - val_loss: 2.1100 - val_accuracy: 0.2258 - lr: 9.7656e-06\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2065 - accuracy: 0.1294 - val_loss: 2.1899 - val_accuracy: 0.2258 - lr: 9.7656e-06\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1952 - accuracy: 0.1647 - val_loss: 2.1778 - val_accuracy: 0.1935 - lr: 9.7656e-06\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1972 - accuracy: 0.1529 - val_loss: 2.0939 - val_accuracy: 0.1290 - lr: 9.7656e-06\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1787 - accuracy: 0.1451 - val_loss: 2.2113 - val_accuracy: 0.2258 - lr: 9.7656e-06\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1814 - accuracy: 0.1451 - val_loss: 2.1723 - val_accuracy: 0.0645 - lr: 9.7656e-06\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1880 - accuracy: 0.1490 - val_loss: 2.2535 - val_accuracy: 0.1613 - lr: 4.8828e-06\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1837 - accuracy: 0.1529 - val_loss: 2.1958 - val_accuracy: 0.1290 - lr: 4.8828e-06\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1777 - accuracy: 0.1529 - val_loss: 2.1822 - val_accuracy: 0.1290 - lr: 4.8828e-06\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2060 - accuracy: 0.1608 - val_loss: 2.1557 - val_accuracy: 0.2258 - lr: 4.8828e-06\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2217 - accuracy: 0.1608 - val_loss: 2.2084 - val_accuracy: 0.0645 - lr: 4.8828e-06\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.2012 - accuracy: 0.1373 - val_loss: 2.1923 - val_accuracy: 0.0968 - lr: 4.8828e-06\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1959 - accuracy: 0.1529 - val_loss: 2.1974 - val_accuracy: 0.1290 - lr: 4.8828e-06\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.2116 - accuracy: 0.1412 - val_loss: 2.2937 - val_accuracy: 0.2258 - lr: 4.8828e-06\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1977 - accuracy: 0.1451 - val_loss: 2.0609 - val_accuracy: 0.1935 - lr: 4.8828e-06\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 2.2062 - accuracy: 0.1608 - val_loss: 2.2304 - val_accuracy: 0.1290 - lr: 4.8828e-06\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1821 - accuracy: 0.1569 - val_loss: 2.3306 - val_accuracy: 0.1613 - lr: 4.8828e-06\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2072 - accuracy: 0.1373 - val_loss: 2.1107 - val_accuracy: 0.1613 - lr: 4.8828e-06\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2008 - accuracy: 0.1569 - val_loss: 2.2440 - val_accuracy: 0.0645 - lr: 4.8828e-06\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1891 - accuracy: 0.1608 - val_loss: 2.1530 - val_accuracy: 0.2258 - lr: 4.8828e-06\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.2063 - accuracy: 0.1412 - val_loss: 2.0528 - val_accuracy: 0.1290 - lr: 4.8828e-06\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2003 - accuracy: 0.1451 - val_loss: 2.1232 - val_accuracy: 0.2258 - lr: 4.8828e-06\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1867 - accuracy: 0.1529 - val_loss: 2.1337 - val_accuracy: 0.1290 - lr: 4.8828e-06\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1974 - accuracy: 0.1490 - val_loss: 2.1049 - val_accuracy: 0.2581 - lr: 4.8828e-06\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1915 - accuracy: 0.1373 - val_loss: 2.1821 - val_accuracy: 0.0968 - lr: 4.8828e-06\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2147 - accuracy: 0.1412 - val_loss: 2.1296 - val_accuracy: 0.1935 - lr: 4.8828e-06\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1992 - accuracy: 0.1451 - val_loss: 2.2387 - val_accuracy: 0.0645 - lr: 2.4414e-06\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1939 - accuracy: 0.1490 - val_loss: 2.1858 - val_accuracy: 0.0645 - lr: 2.4414e-06\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2096 - accuracy: 0.1569 - val_loss: 2.3857 - val_accuracy: 0.0645 - lr: 2.4414e-06\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2052 - accuracy: 0.1490 - val_loss: 2.1872 - val_accuracy: 0.1290 - lr: 2.4414e-06\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2191 - accuracy: 0.1451 - val_loss: 2.2326 - val_accuracy: 0.1290 - lr: 2.4414e-06\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.1804 - accuracy: 0.1490 - val_loss: 2.2203 - val_accuracy: 0.0968 - lr: 2.4414e-06\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1967 - accuracy: 0.1412 - val_loss: 2.2414 - val_accuracy: 0.0968 - lr: 2.4414e-06\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1929 - accuracy: 0.1412 - val_loss: 2.1417 - val_accuracy: 0.1935 - lr: 2.4414e-06\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1923 - accuracy: 0.1412 - val_loss: 2.0981 - val_accuracy: 0.2903 - lr: 2.4414e-06\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1876 - accuracy: 0.1451 - val_loss: 2.1996 - val_accuracy: 0.1290 - lr: 2.4414e-06\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2146 - accuracy: 0.1451 - val_loss: 2.2285 - val_accuracy: 0.2258 - lr: 2.4414e-06\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1786 - accuracy: 0.1569 - val_loss: 2.0931 - val_accuracy: 0.2258 - lr: 2.4414e-06\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1762 - accuracy: 0.1412 - val_loss: 2.2589 - val_accuracy: 0.1613 - lr: 2.4414e-06\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 2.2047 - accuracy: 0.1490 - val_loss: 2.2672 - val_accuracy: 0.0968 - lr: 2.4414e-06\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1746 - accuracy: 0.1294 - val_loss: 2.2344 - val_accuracy: 0.0645 - lr: 2.4414e-06\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1978 - accuracy: 0.1529 - val_loss: 2.1864 - val_accuracy: 0.0645 - lr: 2.4414e-06\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1817 - accuracy: 0.1529 - val_loss: 2.1817 - val_accuracy: 0.1290 - lr: 2.4414e-06\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1736 - accuracy: 0.1412 - val_loss: 2.3372 - val_accuracy: 0.0968 - lr: 2.4414e-06\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2074 - accuracy: 0.1412 - val_loss: 2.1190 - val_accuracy: 0.1935 - lr: 2.4414e-06\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2107 - accuracy: 0.1255 - val_loss: 2.1157 - val_accuracy: 0.0968 - lr: 2.4414e-06\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2008 - accuracy: 0.1412 - val_loss: 2.1899 - val_accuracy: 0.1613 - lr: 1.2207e-06\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2092 - accuracy: 0.1412 - val_loss: 2.2197 - val_accuracy: 0.1290 - lr: 1.2207e-06\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1793 - accuracy: 0.1569 - val_loss: 2.1865 - val_accuracy: 0.1935 - lr: 1.2207e-06\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1998 - accuracy: 0.1569 - val_loss: 2.2150 - val_accuracy: 0.0000e+00 - lr: 1.2207e-06\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1932 - accuracy: 0.1451 - val_loss: 2.3147 - val_accuracy: 0.0645 - lr: 1.2207e-06\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1884 - accuracy: 0.1333 - val_loss: 2.0891 - val_accuracy: 0.1613 - lr: 1.2207e-06\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1897 - accuracy: 0.1412 - val_loss: 2.2343 - val_accuracy: 0.1613 - lr: 1.2207e-06\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1952 - accuracy: 0.1451 - val_loss: 2.1457 - val_accuracy: 0.2258 - lr: 1.2207e-06\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1880 - accuracy: 0.1608 - val_loss: 2.2767 - val_accuracy: 0.0968 - lr: 1.2207e-06\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2173 - accuracy: 0.1373 - val_loss: 2.0960 - val_accuracy: 0.1290 - lr: 1.2207e-06\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2023 - accuracy: 0.1412 - val_loss: 2.1383 - val_accuracy: 0.1613 - lr: 1.2207e-06\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1999 - accuracy: 0.1373 - val_loss: 2.1553 - val_accuracy: 0.0968 - lr: 1.2207e-06\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1825 - accuracy: 0.1490 - val_loss: 2.3663 - val_accuracy: 0.0968 - lr: 1.2207e-06\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1871 - accuracy: 0.1569 - val_loss: 2.1283 - val_accuracy: 0.1290 - lr: 1.2207e-06\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1744 - accuracy: 0.1569 - val_loss: 2.1932 - val_accuracy: 0.2258 - lr: 1.2207e-06\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2013 - accuracy: 0.1294 - val_loss: 2.1169 - val_accuracy: 0.1613 - lr: 1.2207e-06\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2033 - accuracy: 0.1569 - val_loss: 2.2155 - val_accuracy: 0.0645 - lr: 1.2207e-06\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1809 - accuracy: 0.1451 - val_loss: 2.1427 - val_accuracy: 0.2258 - lr: 1.2207e-06\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2230 - accuracy: 0.1373 - val_loss: 2.2220 - val_accuracy: 0.2581 - lr: 1.2207e-06\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2097 - accuracy: 0.1451 - val_loss: 2.2757 - val_accuracy: 0.1290 - lr: 1.2207e-06\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2008 - accuracy: 0.1412 - val_loss: 2.2886 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1855 - accuracy: 0.1333 - val_loss: 2.2458 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2014 - accuracy: 0.1451 - val_loss: 2.1541 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1843 - accuracy: 0.1529 - val_loss: 2.2315 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2208 - accuracy: 0.1137 - val_loss: 2.0850 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.1798 - accuracy: 0.1373 - val_loss: 2.0794 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1993 - accuracy: 0.1490 - val_loss: 2.1516 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2089 - accuracy: 0.1412 - val_loss: 2.1245 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2038 - accuracy: 0.1451 - val_loss: 2.2315 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2150 - accuracy: 0.1333 - val_loss: 2.1251 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2153 - accuracy: 0.1333 - val_loss: 2.3646 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.1976 - accuracy: 0.1451 - val_loss: 2.3236 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2112 - accuracy: 0.1373 - val_loss: 2.1844 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1843 - accuracy: 0.1608 - val_loss: 2.2221 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2018 - accuracy: 0.1725 - val_loss: 2.2511 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1932 - accuracy: 0.1608 - val_loss: 2.1466 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2228 - accuracy: 0.1608 - val_loss: 2.2553 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2075 - accuracy: 0.1529 - val_loss: 2.2210 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2025 - accuracy: 0.1529 - val_loss: 2.2041 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1970 - accuracy: 0.1451 - val_loss: 2.1516 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1752 - accuracy: 0.1451 - val_loss: 2.0843 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1743 - accuracy: 0.1569 - val_loss: 2.1801 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1993 - accuracy: 0.1490 - val_loss: 2.1573 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1965 - accuracy: 0.1294 - val_loss: 2.1221 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2041 - accuracy: 0.1373 - val_loss: 2.2706 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2044 - accuracy: 0.1569 - val_loss: 2.1350 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1818 - accuracy: 0.1490 - val_loss: 2.0625 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1928 - accuracy: 0.1373 - val_loss: 2.2751 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.2005 - accuracy: 0.1451 - val_loss: 2.1991 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1919 - accuracy: 0.1412 - val_loss: 2.1068 - val_accuracy: 0.3226 - lr: 1.0000e-06\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.2004 - accuracy: 0.1608 - val_loss: 2.1984 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1969 - accuracy: 0.1529 - val_loss: 2.0502 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1875 - accuracy: 0.1294 - val_loss: 2.1684 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1935 - accuracy: 0.1529 - val_loss: 2.2992 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2095 - accuracy: 0.1647 - val_loss: 2.2311 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1862 - accuracy: 0.1647 - val_loss: 2.1824 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1865 - accuracy: 0.1608 - val_loss: 2.3762 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2049 - accuracy: 0.1373 - val_loss: 2.2292 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2090 - accuracy: 0.1412 - val_loss: 2.2984 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1926 - accuracy: 0.1529 - val_loss: 2.1542 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2044 - accuracy: 0.1451 - val_loss: 2.2458 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1903 - accuracy: 0.1529 - val_loss: 2.2201 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1911 - accuracy: 0.1608 - val_loss: 2.1726 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 2.1790 - accuracy: 0.1529 - val_loss: 2.1421 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1913 - accuracy: 0.1373 - val_loss: 2.1385 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2151 - accuracy: 0.1608 - val_loss: 2.1809 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1805 - accuracy: 0.1608 - val_loss: 2.2262 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2052 - accuracy: 0.1608 - val_loss: 2.1755 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1918 - accuracy: 0.1451 - val_loss: 2.1871 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2097 - accuracy: 0.1451 - val_loss: 2.1888 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1912 - accuracy: 0.1608 - val_loss: 2.2734 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1924 - accuracy: 0.1451 - val_loss: 2.2250 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2003 - accuracy: 0.1333 - val_loss: 2.2035 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2070 - accuracy: 0.1412 - val_loss: 2.1203 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1825 - accuracy: 0.1608 - val_loss: 2.1909 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1967 - accuracy: 0.1608 - val_loss: 2.1359 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1812 - accuracy: 0.1490 - val_loss: 2.1394 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1945 - accuracy: 0.1294 - val_loss: 2.2015 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2089 - accuracy: 0.1686 - val_loss: 2.2280 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2005 - accuracy: 0.1608 - val_loss: 2.1757 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1986 - accuracy: 0.1490 - val_loss: 2.1166 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2007 - accuracy: 0.1451 - val_loss: 2.1679 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.1960 - accuracy: 0.1490 - val_loss: 2.1163 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2025 - accuracy: 0.1529 - val_loss: 2.1081 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2037 - accuracy: 0.1608 - val_loss: 2.0815 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1819 - accuracy: 0.1569 - val_loss: 2.2448 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2071 - accuracy: 0.1451 - val_loss: 2.1493 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1981 - accuracy: 0.1412 - val_loss: 2.0897 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1901 - accuracy: 0.1686 - val_loss: 2.1531 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1902 - accuracy: 0.1412 - val_loss: 2.1830 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1889 - accuracy: 0.1451 - val_loss: 2.2084 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1966 - accuracy: 0.1373 - val_loss: 2.2547 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.2001 - accuracy: 0.1451 - val_loss: 2.1523 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2007 - accuracy: 0.1412 - val_loss: 2.2237 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2113 - accuracy: 0.1412 - val_loss: 2.2486 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2030 - accuracy: 0.1490 - val_loss: 2.1892 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2042 - accuracy: 0.1451 - val_loss: 2.1023 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1957 - accuracy: 0.1412 - val_loss: 2.1725 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1943 - accuracy: 0.1529 - val_loss: 2.2785 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2063 - accuracy: 0.1451 - val_loss: 2.2191 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2073 - accuracy: 0.1412 - val_loss: 2.1063 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2020 - accuracy: 0.1490 - val_loss: 2.0461 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.2009 - accuracy: 0.1333 - val_loss: 2.2583 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1870 - accuracy: 0.1608 - val_loss: 2.1869 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1921 - accuracy: 0.1451 - val_loss: 2.2223 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.1925 - accuracy: 0.1529 - val_loss: 2.2454 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2111 - accuracy: 0.1451 - val_loss: 2.2335 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1925 - accuracy: 0.1569 - val_loss: 2.2029 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.1807 - accuracy: 0.1686 - val_loss: 2.0683 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2045 - accuracy: 0.1373 - val_loss: 2.2375 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2062 - accuracy: 0.1255 - val_loss: 2.2459 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1909 - accuracy: 0.1569 - val_loss: 2.1598 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2122 - accuracy: 0.1569 - val_loss: 2.3219 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1967 - accuracy: 0.1647 - val_loss: 2.2381 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1973 - accuracy: 0.1490 - val_loss: 2.1130 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1986 - accuracy: 0.1529 - val_loss: 2.3089 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1965 - accuracy: 0.1608 - val_loss: 2.3134 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1878 - accuracy: 0.1529 - val_loss: 2.2505 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 2.1968 - accuracy: 0.1608 - val_loss: 2.2579 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1918 - accuracy: 0.1569 - val_loss: 2.1901 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1768 - accuracy: 0.1529 - val_loss: 2.1500 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1961 - accuracy: 0.1373 - val_loss: 2.1427 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1966 - accuracy: 0.1569 - val_loss: 2.1470 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1931 - accuracy: 0.1451 - val_loss: 2.1331 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2066 - accuracy: 0.1569 - val_loss: 2.1987 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2146 - accuracy: 0.1294 - val_loss: 2.1952 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1940 - accuracy: 0.1451 - val_loss: 2.2390 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1970 - accuracy: 0.1490 - val_loss: 2.3209 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2055 - accuracy: 0.1490 - val_loss: 2.3086 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1993 - accuracy: 0.1569 - val_loss: 2.1224 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2052 - accuracy: 0.1333 - val_loss: 2.1645 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2160 - accuracy: 0.1451 - val_loss: 2.1980 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2164 - accuracy: 0.1490 - val_loss: 2.1892 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1922 - accuracy: 0.1490 - val_loss: 2.0519 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2054 - accuracy: 0.1373 - val_loss: 2.1622 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.1865 - accuracy: 0.1569 - val_loss: 2.3238 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1924 - accuracy: 0.1529 - val_loss: 2.1795 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.1896 - accuracy: 0.1294 - val_loss: 2.1886 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1891 - accuracy: 0.1373 - val_loss: 2.1753 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1935 - accuracy: 0.1529 - val_loss: 2.1646 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2033 - accuracy: 0.1451 - val_loss: 2.1614 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1923 - accuracy: 0.1569 - val_loss: 2.1839 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2195 - accuracy: 0.1333 - val_loss: 2.1776 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2054 - accuracy: 0.1255 - val_loss: 2.2741 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1799 - accuracy: 0.1647 - val_loss: 2.1968 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2147 - accuracy: 0.1490 - val_loss: 2.1454 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2066 - accuracy: 0.1451 - val_loss: 2.1429 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2007 - accuracy: 0.1412 - val_loss: 2.1692 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2101 - accuracy: 0.1373 - val_loss: 2.1459 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.1824 - accuracy: 0.1529 - val_loss: 2.3572 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1903 - accuracy: 0.1529 - val_loss: 2.2444 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2110 - accuracy: 0.1490 - val_loss: 2.2557 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 2.2033 - accuracy: 0.1451 - val_loss: 2.1353 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1888 - accuracy: 0.1647 - val_loss: 2.2409 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2130 - accuracy: 0.1373 - val_loss: 2.2340 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1999 - accuracy: 0.1255 - val_loss: 2.0886 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1977 - accuracy: 0.1373 - val_loss: 2.2959 - val_accuracy: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2125 - accuracy: 0.1373 - val_loss: 2.2632 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1904 - accuracy: 0.1608 - val_loss: 2.1792 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2026 - accuracy: 0.1451 - val_loss: 2.3734 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 2.2088 - accuracy: 0.1490 - val_loss: 2.1740 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2073 - accuracy: 0.1255 - val_loss: 2.1615 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1850 - accuracy: 0.1490 - val_loss: 2.2430 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1965 - accuracy: 0.1569 - val_loss: 2.1105 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1911 - accuracy: 0.1373 - val_loss: 2.3293 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1876 - accuracy: 0.1608 - val_loss: 2.1403 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2050 - accuracy: 0.1529 - val_loss: 2.2879 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2093 - accuracy: 0.1490 - val_loss: 2.0893 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1931 - accuracy: 0.1294 - val_loss: 2.1068 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2139 - accuracy: 0.1569 - val_loss: 2.2454 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.2168 - accuracy: 0.1176 - val_loss: 2.2011 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2014 - accuracy: 0.1373 - val_loss: 2.3196 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2127 - accuracy: 0.1333 - val_loss: 2.1796 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1955 - accuracy: 0.1569 - val_loss: 2.1418 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2012 - accuracy: 0.1490 - val_loss: 2.2910 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2075 - accuracy: 0.1490 - val_loss: 2.1811 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1951 - accuracy: 0.1569 - val_loss: 2.2031 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1968 - accuracy: 0.1490 - val_loss: 2.0193 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 2.1716 - accuracy: 0.1686 - val_loss: 2.3223 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2014 - accuracy: 0.1490 - val_loss: 2.2441 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2006 - accuracy: 0.1569 - val_loss: 2.1744 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.1945 - accuracy: 0.1608 - val_loss: 2.2071 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1933 - accuracy: 0.1529 - val_loss: 2.2025 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2118 - accuracy: 0.1412 - val_loss: 2.2665 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2108 - accuracy: 0.1490 - val_loss: 2.1078 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2009 - accuracy: 0.1294 - val_loss: 2.1403 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.1916 - accuracy: 0.1569 - val_loss: 2.2823 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1824 - accuracy: 0.1686 - val_loss: 2.1206 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1962 - accuracy: 0.1490 - val_loss: 2.1073 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1953 - accuracy: 0.1529 - val_loss: 2.1454 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1980 - accuracy: 0.1451 - val_loss: 2.1886 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1950 - accuracy: 0.1412 - val_loss: 2.1922 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1972 - accuracy: 0.1569 - val_loss: 2.2246 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2234 - accuracy: 0.1373 - val_loss: 2.2158 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.1786 - accuracy: 0.1529 - val_loss: 2.2603 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1955 - accuracy: 0.1529 - val_loss: 2.1898 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1976 - accuracy: 0.1373 - val_loss: 2.2257 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 2.2083 - accuracy: 0.1412 - val_loss: 2.1962 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.2029 - accuracy: 0.1451 - val_loss: 2.1616 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 2.2087 - accuracy: 0.1373 - val_loss: 2.1127 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.1929 - accuracy: 0.1412 - val_loss: 2.2002 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2147 - accuracy: 0.1490 - val_loss: 2.0953 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2059 - accuracy: 0.1412 - val_loss: 2.2977 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.1770 - accuracy: 0.1569 - val_loss: 2.2222 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 2.1790 - accuracy: 0.1490 - val_loss: 2.2879 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1845 - accuracy: 0.1451 - val_loss: 2.3012 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1861 - accuracy: 0.1529 - val_loss: 2.2253 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1788 - accuracy: 0.1412 - val_loss: 2.1050 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1937 - accuracy: 0.1647 - val_loss: 2.1406 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 2.1951 - accuracy: 0.1490 - val_loss: 2.1852 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1672 - accuracy: 0.1647 - val_loss: 2.1141 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1675 - accuracy: 0.1529 - val_loss: 2.1477 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2126 - accuracy: 0.1333 - val_loss: 2.1194 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.1879 - accuracy: 0.1412 - val_loss: 2.3279 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2139 - accuracy: 0.1490 - val_loss: 2.2304 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2160 - accuracy: 0.1412 - val_loss: 2.2280 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2129 - accuracy: 0.1490 - val_loss: 2.1122 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1803 - accuracy: 0.1647 - val_loss: 2.1493 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1972 - accuracy: 0.1373 - val_loss: 2.1154 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2244 - accuracy: 0.1294 - val_loss: 2.1153 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2033 - accuracy: 0.1451 - val_loss: 2.1470 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1989 - accuracy: 0.1373 - val_loss: 2.3027 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1958 - accuracy: 0.1608 - val_loss: 2.3749 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1933 - accuracy: 0.1412 - val_loss: 2.2223 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1886 - accuracy: 0.1333 - val_loss: 2.2081 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1778 - accuracy: 0.1451 - val_loss: 2.0796 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1860 - accuracy: 0.1451 - val_loss: 2.2356 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1984 - accuracy: 0.1412 - val_loss: 2.2454 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.1934 - accuracy: 0.1373 - val_loss: 2.2124 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2151 - accuracy: 0.1569 - val_loss: 2.1634 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1998 - accuracy: 0.1333 - val_loss: 2.2111 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2147 - accuracy: 0.1490 - val_loss: 2.2015 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2002 - accuracy: 0.1333 - val_loss: 2.1697 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1789 - accuracy: 0.1608 - val_loss: 2.2210 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1817 - accuracy: 0.1490 - val_loss: 2.0434 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2094 - accuracy: 0.1529 - val_loss: 2.0764 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2070 - accuracy: 0.1255 - val_loss: 2.1692 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.1944 - accuracy: 0.1412 - val_loss: 2.2176 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2084 - accuracy: 0.1451 - val_loss: 2.1527 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2174 - accuracy: 0.1608 - val_loss: 2.2475 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 2.2017 - accuracy: 0.1569 - val_loss: 2.2302 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.1787 - accuracy: 0.1686 - val_loss: 2.1611 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2136 - accuracy: 0.1412 - val_loss: 2.1334 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2043 - accuracy: 0.1490 - val_loss: 2.2842 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2088 - accuracy: 0.1490 - val_loss: 2.1840 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1954 - accuracy: 0.1412 - val_loss: 2.1009 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1967 - accuracy: 0.1490 - val_loss: 2.3118 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2053 - accuracy: 0.1569 - val_loss: 2.2214 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1808 - accuracy: 0.1569 - val_loss: 2.3111 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2073 - accuracy: 0.1294 - val_loss: 2.2780 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1926 - accuracy: 0.1569 - val_loss: 2.1911 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1968 - accuracy: 0.1412 - val_loss: 2.2102 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1905 - accuracy: 0.1451 - val_loss: 2.1805 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1898 - accuracy: 0.1373 - val_loss: 2.1645 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1866 - accuracy: 0.1373 - val_loss: 2.2357 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1840 - accuracy: 0.1451 - val_loss: 2.2221 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2200 - accuracy: 0.1333 - val_loss: 2.1296 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1986 - accuracy: 0.1451 - val_loss: 2.1998 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1806 - accuracy: 0.1686 - val_loss: 2.1429 - val_accuracy: 0.3226 - lr: 1.0000e-06\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1816 - accuracy: 0.1608 - val_loss: 2.3749 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2088 - accuracy: 0.1490 - val_loss: 2.2118 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1802 - accuracy: 0.1373 - val_loss: 2.1618 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2089 - accuracy: 0.1608 - val_loss: 2.1308 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2121 - accuracy: 0.1529 - val_loss: 2.1888 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2155 - accuracy: 0.1373 - val_loss: 2.2123 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2000 - accuracy: 0.1451 - val_loss: 2.1157 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2048 - accuracy: 0.1412 - val_loss: 2.2343 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1851 - accuracy: 0.1529 - val_loss: 2.1847 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2016 - accuracy: 0.1490 - val_loss: 2.1783 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1750 - accuracy: 0.1647 - val_loss: 2.1955 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2025 - accuracy: 0.1412 - val_loss: 2.1456 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 2.1920 - accuracy: 0.1451 - val_loss: 2.2638 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2295 - accuracy: 0.1608 - val_loss: 2.1667 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.2079 - accuracy: 0.1569 - val_loss: 2.2316 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1899 - accuracy: 0.1255 - val_loss: 2.1547 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2137 - accuracy: 0.1373 - val_loss: 2.1208 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1819 - accuracy: 0.1451 - val_loss: 2.2381 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2195 - accuracy: 0.1529 - val_loss: 2.2175 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1962 - accuracy: 0.1294 - val_loss: 2.2474 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2156 - accuracy: 0.1412 - val_loss: 2.2000 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1993 - accuracy: 0.1373 - val_loss: 2.2392 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2052 - accuracy: 0.1529 - val_loss: 2.1493 - val_accuracy: 0.3226 - lr: 1.0000e-06\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2102 - accuracy: 0.1412 - val_loss: 2.2703 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2155 - accuracy: 0.1294 - val_loss: 2.2343 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1897 - accuracy: 0.1373 - val_loss: 2.2344 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1994 - accuracy: 0.1451 - val_loss: 2.3405 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2175 - accuracy: 0.1529 - val_loss: 2.1860 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1931 - accuracy: 0.1333 - val_loss: 2.2984 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1894 - accuracy: 0.1373 - val_loss: 2.1324 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1950 - accuracy: 0.1569 - val_loss: 2.2595 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 2.2061 - accuracy: 0.1569 - val_loss: 2.1348 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2004 - accuracy: 0.1569 - val_loss: 2.1249 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1927 - accuracy: 0.1373 - val_loss: 2.2920 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1970 - accuracy: 0.1569 - val_loss: 2.0902 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2202 - accuracy: 0.1490 - val_loss: 2.2474 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 2.1959 - accuracy: 0.1686 - val_loss: 2.2683 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2071 - accuracy: 0.1412 - val_loss: 2.2459 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1887 - accuracy: 0.1255 - val_loss: 2.1434 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1865 - accuracy: 0.1451 - val_loss: 2.2260 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2025 - accuracy: 0.1490 - val_loss: 2.1859 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1918 - accuracy: 0.1373 - val_loss: 2.2571 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1938 - accuracy: 0.1608 - val_loss: 2.1616 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 2.2014 - accuracy: 0.1412 - val_loss: 2.1390 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2058 - accuracy: 0.1373 - val_loss: 2.1807 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1783 - accuracy: 0.1647 - val_loss: 2.0735 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.2022 - accuracy: 0.1451 - val_loss: 2.0969 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1879 - accuracy: 0.1294 - val_loss: 2.1147 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1864 - accuracy: 0.1451 - val_loss: 2.3444 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1969 - accuracy: 0.1608 - val_loss: 2.0877 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2182 - accuracy: 0.1412 - val_loss: 2.1653 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1946 - accuracy: 0.1490 - val_loss: 2.2398 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.1899 - accuracy: 0.1451 - val_loss: 2.1270 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2114 - accuracy: 0.1490 - val_loss: 2.2860 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1803 - accuracy: 0.1490 - val_loss: 2.1177 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2020 - accuracy: 0.1373 - val_loss: 2.2301 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2216 - accuracy: 0.1373 - val_loss: 2.1482 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2180 - accuracy: 0.1333 - val_loss: 2.3527 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1890 - accuracy: 0.1647 - val_loss: 2.1013 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2089 - accuracy: 0.1373 - val_loss: 2.3573 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2081 - accuracy: 0.1569 - val_loss: 2.1346 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2025 - accuracy: 0.1373 - val_loss: 2.1922 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 2.1954 - accuracy: 0.1333 - val_loss: 2.3454 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1938 - accuracy: 0.1412 - val_loss: 2.0906 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1976 - accuracy: 0.1451 - val_loss: 2.1043 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1858 - accuracy: 0.1451 - val_loss: 2.1644 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1769 - accuracy: 0.1569 - val_loss: 2.2066 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1853 - accuracy: 0.1451 - val_loss: 2.3603 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1741 - accuracy: 0.1373 - val_loss: 2.2011 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2065 - accuracy: 0.1569 - val_loss: 2.1278 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1835 - accuracy: 0.1294 - val_loss: 2.2742 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1899 - accuracy: 0.1451 - val_loss: 2.0882 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2122 - accuracy: 0.1333 - val_loss: 2.1750 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1912 - accuracy: 0.1451 - val_loss: 2.1283 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2142 - accuracy: 0.1373 - val_loss: 2.2207 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2001 - accuracy: 0.1490 - val_loss: 2.1834 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1912 - accuracy: 0.1529 - val_loss: 2.1705 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2039 - accuracy: 0.1490 - val_loss: 2.0815 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2088 - accuracy: 0.1569 - val_loss: 2.1643 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2012 - accuracy: 0.1529 - val_loss: 2.1647 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1903 - accuracy: 0.1569 - val_loss: 2.1706 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1923 - accuracy: 0.1451 - val_loss: 2.1751 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1917 - accuracy: 0.1529 - val_loss: 2.1685 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2006 - accuracy: 0.1412 - val_loss: 2.2292 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1951 - accuracy: 0.1373 - val_loss: 2.1352 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1638 - accuracy: 0.1569 - val_loss: 2.2598 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1922 - accuracy: 0.1529 - val_loss: 2.2721 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1857 - accuracy: 0.1608 - val_loss: 2.2178 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1905 - accuracy: 0.1608 - val_loss: 2.2390 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1830 - accuracy: 0.1608 - val_loss: 2.1271 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1952 - accuracy: 0.1529 - val_loss: 2.0648 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2081 - accuracy: 0.1647 - val_loss: 2.1014 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1987 - accuracy: 0.1333 - val_loss: 2.2474 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.2103 - accuracy: 0.1412 - val_loss: 2.2464 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1913 - accuracy: 0.1569 - val_loss: 2.2501 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1792 - accuracy: 0.1608 - val_loss: 2.2474 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1939 - accuracy: 0.1569 - val_loss: 2.1839 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2119 - accuracy: 0.1333 - val_loss: 2.1884 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1865 - accuracy: 0.1451 - val_loss: 2.2923 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1879 - accuracy: 0.1569 - val_loss: 2.0900 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1886 - accuracy: 0.1490 - val_loss: 2.1908 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 2.1859 - accuracy: 0.1490 - val_loss: 2.3619 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2022 - accuracy: 0.1373 - val_loss: 2.2765 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2171 - accuracy: 0.1333 - val_loss: 2.2131 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2080 - accuracy: 0.1490 - val_loss: 2.1644 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2016 - accuracy: 0.1333 - val_loss: 2.0934 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1731 - accuracy: 0.1647 - val_loss: 2.2864 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1908 - accuracy: 0.1686 - val_loss: 2.1343 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1868 - accuracy: 0.1373 - val_loss: 2.1644 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2149 - accuracy: 0.1490 - val_loss: 2.2203 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1951 - accuracy: 0.1529 - val_loss: 2.1530 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2070 - accuracy: 0.1529 - val_loss: 2.2262 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1968 - accuracy: 0.1451 - val_loss: 2.2049 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1772 - accuracy: 0.1529 - val_loss: 2.1344 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.2033 - accuracy: 0.1451 - val_loss: 2.1678 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2036 - accuracy: 0.1569 - val_loss: 2.3104 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1940 - accuracy: 0.1529 - val_loss: 2.1086 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1941 - accuracy: 0.1451 - val_loss: 2.1393 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1861 - accuracy: 0.1608 - val_loss: 2.1857 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1931 - accuracy: 0.1451 - val_loss: 2.2487 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2108 - accuracy: 0.1490 - val_loss: 2.1503 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1978 - accuracy: 0.1569 - val_loss: 2.2010 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1833 - accuracy: 0.1451 - val_loss: 2.2562 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 2.2102 - accuracy: 0.1412 - val_loss: 2.3452 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2151 - accuracy: 0.1490 - val_loss: 2.1697 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1915 - accuracy: 0.1647 - val_loss: 2.1872 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1902 - accuracy: 0.1451 - val_loss: 2.1806 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.2028 - accuracy: 0.1373 - val_loss: 2.2547 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2072 - accuracy: 0.1294 - val_loss: 2.3521 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2010 - accuracy: 0.1451 - val_loss: 2.2181 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1778 - accuracy: 0.1412 - val_loss: 2.1868 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2082 - accuracy: 0.1569 - val_loss: 2.2331 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1839 - accuracy: 0.1490 - val_loss: 2.1564 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2124 - accuracy: 0.1373 - val_loss: 2.1509 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2022 - accuracy: 0.1333 - val_loss: 2.2035 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2218 - accuracy: 0.1294 - val_loss: 2.1910 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1995 - accuracy: 0.1412 - val_loss: 2.3324 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2129 - accuracy: 0.1490 - val_loss: 2.2713 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1926 - accuracy: 0.1686 - val_loss: 2.1434 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2115 - accuracy: 0.1412 - val_loss: 2.1643 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1984 - accuracy: 0.1529 - val_loss: 2.1881 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2111 - accuracy: 0.1451 - val_loss: 2.2545 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 2.1983 - accuracy: 0.1333 - val_loss: 2.2352 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1929 - accuracy: 0.1529 - val_loss: 2.2519 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1939 - accuracy: 0.1569 - val_loss: 2.2199 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1923 - accuracy: 0.1686 - val_loss: 2.2465 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1880 - accuracy: 0.1490 - val_loss: 2.2371 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1858 - accuracy: 0.1333 - val_loss: 2.1533 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1887 - accuracy: 0.1647 - val_loss: 2.2633 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2062 - accuracy: 0.1529 - val_loss: 2.2462 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2046 - accuracy: 0.1373 - val_loss: 2.3202 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 2.1736 - accuracy: 0.1490 - val_loss: 2.3301 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 2.1984 - accuracy: 0.1490 - val_loss: 2.0579 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2033 - accuracy: 0.1333 - val_loss: 2.1074 - val_accuracy: 0.3226 - lr: 1.0000e-06\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.1939 - accuracy: 0.1373 - val_loss: 2.2525 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2001 - accuracy: 0.1412 - val_loss: 2.2385 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1872 - accuracy: 0.1490 - val_loss: 2.1903 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1913 - accuracy: 0.1608 - val_loss: 2.0632 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2060 - accuracy: 0.1451 - val_loss: 2.1715 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2094 - accuracy: 0.1490 - val_loss: 2.1979 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2017 - accuracy: 0.1608 - val_loss: 2.2014 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2018 - accuracy: 0.1373 - val_loss: 2.4016 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1991 - accuracy: 0.1529 - val_loss: 2.1431 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2206 - accuracy: 0.1412 - val_loss: 2.0950 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1678 - accuracy: 0.1490 - val_loss: 2.1292 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2000 - accuracy: 0.1608 - val_loss: 2.1945 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1852 - accuracy: 0.1294 - val_loss: 2.1366 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2015 - accuracy: 0.1529 - val_loss: 2.0443 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 2.1958 - accuracy: 0.1373 - val_loss: 2.2277 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1808 - accuracy: 0.1569 - val_loss: 2.1270 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1954 - accuracy: 0.1529 - val_loss: 2.0939 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.2084 - accuracy: 0.1608 - val_loss: 2.2398 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1950 - accuracy: 0.1647 - val_loss: 2.2046 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.1998 - accuracy: 0.1608 - val_loss: 2.0812 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1901 - accuracy: 0.1490 - val_loss: 2.2780 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1925 - accuracy: 0.1373 - val_loss: 2.1555 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1877 - accuracy: 0.1490 - val_loss: 2.1702 - val_accuracy: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1879 - accuracy: 0.1569 - val_loss: 2.2887 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1857 - accuracy: 0.1490 - val_loss: 2.0984 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1901 - accuracy: 0.1451 - val_loss: 2.0865 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1992 - accuracy: 0.1647 - val_loss: 2.1497 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2066 - accuracy: 0.1294 - val_loss: 2.1004 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1974 - accuracy: 0.1569 - val_loss: 2.1476 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1947 - accuracy: 0.1373 - val_loss: 2.2027 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1962 - accuracy: 0.1451 - val_loss: 2.2093 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1859 - accuracy: 0.1529 - val_loss: 2.1477 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1850 - accuracy: 0.1333 - val_loss: 2.2019 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2074 - accuracy: 0.1451 - val_loss: 2.1794 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1729 - accuracy: 0.1569 - val_loss: 2.1816 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2160 - accuracy: 0.1373 - val_loss: 2.1270 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1923 - accuracy: 0.1373 - val_loss: 2.2419 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 2.1964 - accuracy: 0.1569 - val_loss: 2.3024 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1936 - accuracy: 0.1686 - val_loss: 2.0806 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2073 - accuracy: 0.1412 - val_loss: 2.2735 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 2.2020 - accuracy: 0.1608 - val_loss: 2.2803 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2034 - accuracy: 0.1373 - val_loss: 2.2079 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1855 - accuracy: 0.1608 - val_loss: 2.1507 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 2.1983 - accuracy: 0.1608 - val_loss: 2.1758 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2298 - accuracy: 0.1412 - val_loss: 2.3042 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1998 - accuracy: 0.1529 - val_loss: 2.1183 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 2.2029 - accuracy: 0.1569 - val_loss: 2.2448 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.2064 - accuracy: 0.1608 - val_loss: 2.2566 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2085 - accuracy: 0.1529 - val_loss: 2.1613 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 2.2052 - accuracy: 0.1490 - val_loss: 2.3092 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2016 - accuracy: 0.1529 - val_loss: 2.2349 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1867 - accuracy: 0.1412 - val_loss: 2.1708 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2021 - accuracy: 0.1451 - val_loss: 2.1943 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2147 - accuracy: 0.1373 - val_loss: 2.1343 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1905 - accuracy: 0.1608 - val_loss: 2.2194 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 2.1928 - accuracy: 0.1569 - val_loss: 2.0294 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2118 - accuracy: 0.1255 - val_loss: 2.1901 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2140 - accuracy: 0.1333 - val_loss: 2.1983 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 2.2058 - accuracy: 0.1569 - val_loss: 2.1696 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 2.1832 - accuracy: 0.1569 - val_loss: 2.3104 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.2035 - accuracy: 0.1412 - val_loss: 2.1433 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 2.1677 - accuracy: 0.1686 - val_loss: 2.1531 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1843 - accuracy: 0.1569 - val_loss: 2.3228 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2072 - accuracy: 0.1373 - val_loss: 2.2760 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2020 - accuracy: 0.1412 - val_loss: 2.1723 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2070 - accuracy: 0.1412 - val_loss: 2.1363 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1750 - accuracy: 0.1608 - val_loss: 2.1585 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.1935 - accuracy: 0.1451 - val_loss: 2.0752 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.2056 - accuracy: 0.1608 - val_loss: 2.2669 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.2033 - accuracy: 0.1333 - val_loss: 2.1766 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.1875 - accuracy: 0.1569 - val_loss: 2.2016 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1862 - accuracy: 0.1451 - val_loss: 2.2383 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2108 - accuracy: 0.1333 - val_loss: 2.1973 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 2.1977 - accuracy: 0.1451 - val_loss: 2.1062 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1990 - accuracy: 0.1608 - val_loss: 2.1878 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1704 - accuracy: 0.1529 - val_loss: 2.2684 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 2.1946 - accuracy: 0.1451 - val_loss: 2.2588 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1924 - accuracy: 0.1412 - val_loss: 2.1806 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 2.1905 - accuracy: 0.1490 - val_loss: 2.1840 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2001 - accuracy: 0.1647 - val_loss: 2.1156 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2050 - accuracy: 0.1529 - val_loss: 2.3377 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.1941 - accuracy: 0.1412 - val_loss: 2.2778 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2037 - accuracy: 0.1412 - val_loss: 2.2024 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1802 - accuracy: 0.1490 - val_loss: 2.1473 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1920 - accuracy: 0.1490 - val_loss: 2.1201 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 2.2154 - accuracy: 0.1373 - val_loss: 2.0823 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 2.1744 - accuracy: 0.1569 - val_loss: 2.0734 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 2s 254ms/step - loss: 2.1982 - accuracy: 0.1529 - val_loss: 2.1935 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 2.1764 - accuracy: 0.1647 - val_loss: 2.2233 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 2.1993 - accuracy: 0.1412 - val_loss: 2.2358 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 2.2084 - accuracy: 0.1412 - val_loss: 2.1388 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.1722 - accuracy: 0.1451 - val_loss: 2.2479 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.2066 - accuracy: 0.1412 - val_loss: 2.3159 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1740 - accuracy: 0.1529 - val_loss: 2.3695 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 2.1808 - accuracy: 0.1451 - val_loss: 2.2650 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.1909 - accuracy: 0.1255 - val_loss: 2.2954 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2020 - accuracy: 0.1608 - val_loss: 2.1449 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2114 - accuracy: 0.1412 - val_loss: 2.2705 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2022 - accuracy: 0.1294 - val_loss: 2.1463 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1867 - accuracy: 0.1608 - val_loss: 2.1521 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1886 - accuracy: 0.1490 - val_loss: 2.2203 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 2.2091 - accuracy: 0.1412 - val_loss: 2.2003 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 2.1785 - accuracy: 0.1490 - val_loss: 2.2400 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 2.2125 - accuracy: 0.1451 - val_loss: 2.2146 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 2.1987 - accuracy: 0.1373 - val_loss: 2.1494 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 2.1865 - accuracy: 0.1529 - val_loss: 2.2615 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.1991 - accuracy: 0.1529 - val_loss: 2.1494 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2118 - accuracy: 0.1490 - val_loss: 2.1873 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1719 - accuracy: 0.1608 - val_loss: 2.1616 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 2.2155 - accuracy: 0.1373 - val_loss: 2.2573 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2090 - accuracy: 0.1490 - val_loss: 2.0794 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1658 - accuracy: 0.1529 - val_loss: 2.2007 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1923 - accuracy: 0.1490 - val_loss: 2.2691 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.2146 - accuracy: 0.1529 - val_loss: 2.2403 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.1947 - accuracy: 0.1647 - val_loss: 2.1781 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.2013 - accuracy: 0.1373 - val_loss: 2.2087 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1770 - accuracy: 0.1569 - val_loss: 2.2147 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.2060 - accuracy: 0.1451 - val_loss: 2.2084 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 2s 172ms/step - loss: 2.2084 - accuracy: 0.1333 - val_loss: 2.0541 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2025 - accuracy: 0.1412 - val_loss: 2.2319 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 2.1924 - accuracy: 0.1373 - val_loss: 2.2367 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 2.2023 - accuracy: 0.1412 - val_loss: 2.3145 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 2s 170ms/step - loss: 2.2142 - accuracy: 0.1373 - val_loss: 2.2397 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 2s 173ms/step - loss: 2.1892 - accuracy: 0.1490 - val_loss: 2.2325 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 2.1914 - accuracy: 0.1412 - val_loss: 2.0979 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 2s 171ms/step - loss: 2.1970 - accuracy: 0.1490 - val_loss: 2.1310 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 2s 173ms/step - loss: 2.2031 - accuracy: 0.1529 - val_loss: 2.0942 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 2s 171ms/step - loss: 2.1839 - accuracy: 0.1490 - val_loss: 2.1259 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 2s 172ms/step - loss: 2.1797 - accuracy: 0.1490 - val_loss: 2.1751 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 2s 175ms/step - loss: 2.2141 - accuracy: 0.1490 - val_loss: 2.2013 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 2s 174ms/step - loss: 2.2015 - accuracy: 0.1608 - val_loss: 2.1636 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 2s 171ms/step - loss: 2.2108 - accuracy: 0.1451 - val_loss: 2.3171 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 2s 173ms/step - loss: 2.1798 - accuracy: 0.1608 - val_loss: 2.1664 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 2s 174ms/step - loss: 2.1976 - accuracy: 0.1255 - val_loss: 2.1064 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 2s 175ms/step - loss: 2.2273 - accuracy: 0.1255 - val_loss: 2.2915 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 2.1811 - accuracy: 0.1490 - val_loss: 2.2332 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 2s 177ms/step - loss: 2.2060 - accuracy: 0.1529 - val_loss: 2.1039 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 2s 174ms/step - loss: 2.2035 - accuracy: 0.1451 - val_loss: 2.1430 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 2s 175ms/step - loss: 2.1876 - accuracy: 0.1412 - val_loss: 2.2167 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 2s 176ms/step - loss: 2.2060 - accuracy: 0.1451 - val_loss: 2.2637 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2019 - accuracy: 0.1451 - val_loss: 2.1582 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 2s 175ms/step - loss: 2.1949 - accuracy: 0.1451 - val_loss: 2.2165 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 2.1809 - accuracy: 0.1529 - val_loss: 2.2535 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 2s 170ms/step - loss: 2.2067 - accuracy: 0.1490 - val_loss: 2.2984 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 2.2109 - accuracy: 0.1451 - val_loss: 2.1733 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1951 - accuracy: 0.1490 - val_loss: 2.2092 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 2.1917 - accuracy: 0.1412 - val_loss: 2.1991 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.1997 - accuracy: 0.1451 - val_loss: 2.0976 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1981 - accuracy: 0.1412 - val_loss: 2.2743 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 2s 171ms/step - loss: 2.2067 - accuracy: 0.1569 - val_loss: 2.1974 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 2s 170ms/step - loss: 2.1966 - accuracy: 0.1412 - val_loss: 2.1868 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 2s 176ms/step - loss: 2.1921 - accuracy: 0.1569 - val_loss: 2.2161 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 2s 173ms/step - loss: 2.2039 - accuracy: 0.1412 - val_loss: 2.2539 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 2s 170ms/step - loss: 2.2098 - accuracy: 0.1529 - val_loss: 2.2540 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 2s 171ms/step - loss: 2.2086 - accuracy: 0.1373 - val_loss: 2.1527 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1990 - accuracy: 0.1490 - val_loss: 2.2208 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.1915 - accuracy: 0.1490 - val_loss: 2.2415 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 2s 170ms/step - loss: 2.2061 - accuracy: 0.1373 - val_loss: 2.1994 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1843 - accuracy: 0.1490 - val_loss: 2.3397 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 2.2069 - accuracy: 0.1451 - val_loss: 2.2230 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1974 - accuracy: 0.1451 - val_loss: 2.2359 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.1989 - accuracy: 0.1490 - val_loss: 2.1148 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2081 - accuracy: 0.1333 - val_loss: 2.3277 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2030 - accuracy: 0.1451 - val_loss: 2.1588 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2067 - accuracy: 0.1412 - val_loss: 2.2492 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.1971 - accuracy: 0.1412 - val_loss: 2.1143 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 2.2010 - accuracy: 0.1333 - val_loss: 2.2050 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 2.1999 - accuracy: 0.1569 - val_loss: 2.1117 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 2.2161 - accuracy: 0.1412 - val_loss: 2.2546 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 2.2021 - accuracy: 0.1451 - val_loss: 2.3061 - val_accuracy: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 2.2004 - accuracy: 0.1529 - val_loss: 2.1610 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.2005 - accuracy: 0.1529 - val_loss: 2.1814 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.2000 - accuracy: 0.1490 - val_loss: 2.2104 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.1984 - accuracy: 0.1294 - val_loss: 2.1134 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2031 - accuracy: 0.1373 - val_loss: 2.1590 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 2.1948 - accuracy: 0.1373 - val_loss: 2.1583 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1876 - accuracy: 0.1529 - val_loss: 2.0381 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.2024 - accuracy: 0.1333 - val_loss: 2.0844 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.2223 - accuracy: 0.1255 - val_loss: 2.2054 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2080 - accuracy: 0.1412 - val_loss: 2.2021 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 2.2034 - accuracy: 0.1490 - val_loss: 2.1714 - val_accuracy: 0.2581 - lr: 1.0000e-06\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 2.2098 - accuracy: 0.1294 - val_loss: 2.2020 - val_accuracy: 0.2903 - lr: 1.0000e-06\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 2.1707 - accuracy: 0.1490 - val_loss: 2.2189 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.2036 - accuracy: 0.1216 - val_loss: 2.1815 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 2.1915 - accuracy: 0.1490 - val_loss: 2.1512 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 2.2049 - accuracy: 0.1294 - val_loss: 2.2266 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 2.1983 - accuracy: 0.1333 - val_loss: 2.2271 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 2.1932 - accuracy: 0.1529 - val_loss: 2.3113 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.1916 - accuracy: 0.1529 - val_loss: 2.2106 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.2100 - accuracy: 0.1490 - val_loss: 2.1529 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.2153 - accuracy: 0.1451 - val_loss: 2.2608 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 2.2046 - accuracy: 0.1490 - val_loss: 2.0917 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 2.1868 - accuracy: 0.1451 - val_loss: 2.2302 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1910 - accuracy: 0.1608 - val_loss: 2.1131 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 2.2041 - accuracy: 0.1529 - val_loss: 2.2025 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 2s 174ms/step - loss: 2.1737 - accuracy: 0.1529 - val_loss: 2.2146 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 2s 175ms/step - loss: 2.2007 - accuracy: 0.1569 - val_loss: 2.1182 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.2026 - accuracy: 0.1373 - val_loss: 2.1480 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.1770 - accuracy: 0.1529 - val_loss: 2.2962 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 2.2031 - accuracy: 0.1333 - val_loss: 2.1542 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 2.2110 - accuracy: 0.1529 - val_loss: 2.1339 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 2.1917 - accuracy: 0.1569 - val_loss: 2.2831 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 2s 193ms/step - loss: 2.1965 - accuracy: 0.1569 - val_loss: 2.2796 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 2.2103 - accuracy: 0.1373 - val_loss: 2.2212 - val_accuracy: 0.0645 - lr: 1.0000e-06\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 2.2218 - accuracy: 0.1216 - val_loss: 2.1470 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 2.2120 - accuracy: 0.1569 - val_loss: 2.2603 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 2.1965 - accuracy: 0.1412 - val_loss: 2.1549 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 2.2003 - accuracy: 0.1490 - val_loss: 2.0950 - val_accuracy: 0.0323 - lr: 1.0000e-06\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 2s 175ms/step - loss: 2.2179 - accuracy: 0.1647 - val_loss: 2.1354 - val_accuracy: 0.2258 - lr: 1.0000e-06\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 2s 176ms/step - loss: 2.2144 - accuracy: 0.1216 - val_loss: 2.1732 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 2.2133 - accuracy: 0.1647 - val_loss: 2.2278 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 2.2107 - accuracy: 0.1529 - val_loss: 2.1059 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 2.1960 - accuracy: 0.1451 - val_loss: 2.1127 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 2s 184ms/step - loss: 2.2031 - accuracy: 0.1569 - val_loss: 2.1968 - val_accuracy: 0.0968 - lr: 1.0000e-06\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 2.1932 - accuracy: 0.1451 - val_loss: 2.2628 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 2.1876 - accuracy: 0.1529 - val_loss: 2.2292 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 2.1878 - accuracy: 0.1569 - val_loss: 2.1739 - val_accuracy: 0.1290 - lr: 1.0000e-06\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 2.1939 - accuracy: 0.1569 - val_loss: 2.2594 - val_accuracy: 0.1613 - lr: 1.0000e-06\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 2s 187ms/step - loss: 2.2086 - accuracy: 0.1373 - val_loss: 2.2748 - val_accuracy: 0.1935 - lr: 1.0000e-06\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 2.2127 - accuracy: 0.1451 - val_loss: 2.1468 - val_accuracy: 0.0323 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(train_ds, validation_data=val_ds, epochs=config.epoch, callbacks=[lr_callback, wandb_callback])\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=config.epoch, callbacks=[lr_callback, wandb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL = \"models/vague-totem-27\"\n",
    "model.save('{}.h5'.format(TRIAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.055664783546946595"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.uniform(-6, 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8797012649422729"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 ** a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None, 258), (None, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12528/1074660846.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrue_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_categories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \"\"\"\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(test_ds)\n",
    "\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "true_categories = tf.concat([y for x, y in test_ds], axis=0)\n",
    "\n",
    "confusion_matrix(predicted_categories, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in test_ds:   # use dataset.unbatch() with repeat\n",
    "   # append true labels\n",
    "   y_true.append(label_batch)\n",
    "   # compute predictions\n",
    "   preds = model.predict(image_batch)\n",
    "   # append predicted labels\n",
    "   y_pred.append(np.argmax(preds, axis = - 1))\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(33, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(33,), dtype=int64, numpy=\n",
       "array([3, 6, 8, 9, 3, 9, 2, 7, 8, 3, 5, 8, 7, 0, 0, 7, 0, 2, 0, 1, 2, 9,\n",
       "       2, 4, 8, 9, 0, 7, 0, 0, 7, 8, 4], dtype=int64)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dtype of argument `keys` must be <dtype: 'string'>, received: <dtype: 'int64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12528/3351285211.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12528/1629337867.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(label)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     return tf.one_hot(\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mids_from_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     )\n",
      "\u001b[1;32md:\\FYP\\sign-recognition\\ActionDetectionforSignLanguage-main\\ActionDetectionforSignLanguage-main\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py\u001b[0m in \u001b[0;36mlookup\u001b[1;34m(self, keys, name)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m       raise TypeError(f\"Dtype of argument `keys` must be {self._key_dtype}, \"\n\u001b[0m\u001b[0;32m    254\u001b[0m                       f\"received: {keys.dtype}\")\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Dtype of argument `keys` must be <dtype: 'string'>, received: <dtype: 'int64'>"
     ]
    }
   ],
   "source": [
    "to_categorical(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
